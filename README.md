# ğŸš€ Orchestrator Agent - Plateforme IA Multi-Providers SÃ©curisÃ©e

[![Security Status](https://img.shields.io/badge/Security-Production%20Ready-green.svg)](./docs/VALIDATION_MICRO_JALON_4_1_A.md)
[![Providers](https://img.shields.io/badge/LLM%20Providers-8%20Supported-blue.svg)](#-fournisseurs-llm-supportÃ©s)
[![Architecture](https://img.shields.io/badge/Architecture-Hexagonale-orange.svg)](#ï¸-architecture-hexagonale)
[![Tests](https://img.shields.io/badge/Tests-9%2F9%20Passing-brightgreen.svg)](./tests/test_micro_jalon_4_1_a.py)

Une plateforme d'orchestration IA **sÃ©curisÃ©e de niveau entreprise** avec support de **8 fournisseurs LLM**, **sessions persistantes**, **mÃ©moire automatique** et **validation de sÃ©curitÃ© complÃ¨te**.

## ğŸŒŸ Vue d'ensemble

Cette plateforme rÃ©volutionnaire offre une API RESTful unifiÃ©e pour orchestrer des conversations IA avec une architecture modulaire **Production-Ready**, supportant 8 grands fournisseurs LLM avec **sÃ©curitÃ© renforcÃ©e**, gestion avancÃ©e de sessions et mÃ©moire automatique.

### âœ¨ CaractÃ©ristiques Principales

- **ğŸ›¡ï¸ SÃ©curitÃ© Enterprise** : Validation des clÃ©s API, CORS sÃ©curisÃ©, masquage automatique
- **ğŸ¯ 8 Fournisseurs LLM** : OpenAI, Anthropic, Google Gemini, Mistral, Grok (xAI), Qwen, DeepSeek, Kimi K2
- **ğŸ’¾ Sessions Persistantes** : Conversations continues avec IDs uniques
- **ğŸ§  MÃ©moire Automatique** : RÃ©sumÃ© automatique de l'historique (configurable)
- **ğŸ”„ Orchestration Intelligente** : Bascule transparente entre providers
- **ğŸ“Š MÃ©triques ComplÃ¨tes** : Tracking dÃ©taillÃ© des performances et usage
- **ğŸ—ï¸ Architecture Hexagonale** : Clean Architecture avec principes SOLID
- **ğŸ“š Documentation Auto** : Swagger/OpenAPI complet
- **ğŸ” Health Monitoring** : Surveillance en temps rÃ©el de tous les providers
- **âœ… Tests AutomatisÃ©s** : Suite complÃ¨te de validation sÃ©curisÃ©e

## ğŸ›ï¸ Architecture Hexagonale SÃ©curisÃ©e

### Structure Modulaire ComplÃ¨te

```
src/
â”œâ”€â”€ api/                                    # ğŸŒ Couche API (FastAPI)
â”‚   â””â”€â”€ router.py                          # Endpoints RESTful complets
â”œâ”€â”€ domain/                                # ğŸ§© Couche MÃ©tier
â”‚   â”œâ”€â”€ llm_service_interface.py           # Interface unifiÃ©e LLM
â”‚   â”œâ”€â”€ llm_service_factory.py             # Factory 8-providers
â”‚   â”œâ”€â”€ session_manager.py                 # Gestionnaire sessions avancÃ©
â”‚   â””â”€â”€ history_summarizer.py              # SynthÃ¨se automatique
â”œâ”€â”€ infrastructure/                        # ğŸ”§ Couche Infrastructure
â”‚   â”œâ”€â”€ secure_api_key_handler.py          # ğŸ›¡ï¸ NOUVEAU: SÃ©curitÃ© centralisÃ©e
â”‚   â”œâ”€â”€ llm_providers/                     # 8 Adaptateurs LLM SÃ©curisÃ©s
â”‚   â”‚   â”œâ”€â”€ openai_adapter.py              # GPT-3.5/4, GPT-4o, O1
â”‚   â”‚   â”œâ”€â”€ anthropic_adapter.py           # Claude 3.5 Sonnet/Haiku
â”‚   â”‚   â”œâ”€â”€ gemini_adapter.py              # Gemini 1.5 Pro/Flash
â”‚   â”‚   â”œâ”€â”€ mistral_adapter.py             # Mistral Large/Small
â”‚   â”‚   â”œâ”€â”€ grok_adapter.py                # Grok (xAI)
â”‚   â”‚   â”œâ”€â”€ qwen_adapter.py                # Qwen/DashScope
â”‚   â”‚   â”œâ”€â”€ deepseek_adapter.py            # DeepSeek V3
â”‚   â”‚   â””â”€â”€ kimi_k2_adapter.py             # Kimi K2
â”‚   â””â”€â”€ session_storage.py                 # Persistance sessions
â”œâ”€â”€ models/                                # ğŸ“‹ ModÃ¨les de DonnÃ©es
â”‚   â””â”€â”€ data_contracts.py                  # Contrats Pydantic complets
â””â”€â”€ tests/                                 # ğŸ§ª Tests AutomatisÃ©s
    â””â”€â”€ test_micro_jalon_4_1_a.py          # ğŸ›¡ï¸ Suite validation sÃ©curitÃ©
```

### ğŸ›¡ï¸ Module de SÃ©curitÃ© CentralisÃ©

Le nouveau module `secure_api_key_handler.py` garantit :
- **Validation stricte** des formats de clÃ©s API par fournisseur
- **Masquage automatique** dans tous les logs et erreurs
- **Gestion d'erreurs sÃ©curisÃ©e** sans exposition de secrets
- **Configuration CORS environnement-aware**

### Gestion AvancÃ©e des Sessions

```mermaid
graph LR
    A[Client Request] --> B[Session Manager]
    B --> C{Session Exists?}
    C -->|Yes| D[Load History]
    C -->|No| E[Create Session]
    D --> F[Check Summary Threshold]
    E --> F
    F --> G{Need Summary?}
    G -->|Yes| H[Auto Summarize]
    G -->|No| I[Direct Processing]
    H --> I
    I --> J[LLM Provider]
    J --> K[Update Session]
    K --> L[Response]
```

## ğŸš€ Installation & Configuration SÃ©curisÃ©e

### ğŸ”§ Installation Standard

```bash
# Cloner le repository
git clone https://github.com/sylvainbonnecarrere/A-IR-OB1.git
cd A-IR-OB1

# Environnement virtuel Python 3.11+
python -m venv .venv
.venv\Scripts\activate     # Windows
source .venv/bin/activate  # Linux/Mac

# Installation des dÃ©pendances
pip install -r requirements.txt
```

### ğŸ›¡ï¸ Configuration SÃ©curisÃ©e des API Keys

**1. Copiez le template de configuration :**
```bash
cp .env.example .env
```

**2. Configurez vos clÃ©s API dans `.env` :**

```env
# ==============================================
# CONFIGURATION GÃ‰NÃ‰RALE SÃ‰CURISÃ‰E
# ==============================================

# Environnement (development, staging, production)
ENVIRONMENT=development

# Configuration CORS (OBLIGATOIRE en production)
CORS_ALLOWED_ORIGINS=https://yourapp.com,https://admin.yourapp.com

# ==============================================
# CLÃ‰S API DES 8 FOURNISSEURS LLM
# ==============================================

# OpenAI (GPT-3.5, GPT-4, GPT-4o, O1)
OPENAI_API_KEY=sk-...

# Anthropic (Claude 3.5 Sonnet/Haiku)
ANTHROPIC_API_KEY=sk-ant-api03-...

# Google Gemini (1.5 Pro/Flash)
GEMINI_API_KEY=AIzaSy...

# Mistral (Large/Small)
MISTRAL_API_KEY=...

# Grok (xAI)
GROK_API_KEY=xai-...

# Qwen/DashScope (Alibaba)
QWEN_API_KEY=sk-...

# DeepSeek V3
DEEPSEEK_API_KEY=sk-...

# Kimi K2 (Moonshot)
KIMI_K2_API_KEY=sk-...
```

### âš ï¸ PrÃ©requis de SÃ©curitÃ©

**En production, l'application validera automatiquement :**
- âœ… Format des clÃ©s API selon les patterns officiels
- âœ… Configuration CORS avec domaines spÃ©cifiques
- âœ… Au moins une clÃ© API valide configurÃ©e
- âœ… Variables d'environnement de sÃ©curitÃ© obligatoires

**L'application refusera de dÃ©marrer si ces conditions ne sont pas remplies.**

### 3. Configuration AvancÃ©e (Optionnel)

```env
# Configuration des sessions
SESSION_SUMMARIZATION_THRESHOLD=20
SESSION_MAX_DURATION_MINUTES=180

# Configuration du serveur
SERVER_PORT=8000
SERVER_HOST=0.0.0.0
LOG_LEVEL=INFO

# Monitoring (Jalon 4.1-B)
MONITORING_ENABLED=true
METRICS_COLLECTION_INTERVAL=30
```

## ğŸ’» DÃ©marrage et Utilisation

### ğŸš€ DÃ©marrage du Serveur

```bash
# DÃ©marrage simple
python main.py

# Ou avec Uvicorn (recommandÃ© pour production)
uvicorn main:app --host 0.0.0.0 --port 8000

# Ou utiliser les scripts fournis
./start.sh        # Linux/Mac
start.bat         # Windows
```

**âœ… Validation au dÃ©marrage :**
```
ğŸ›¡ï¸ Validation sÃ©curisÃ©e des clÃ©s API...
âœ… OpenAI: sk-****cdef (VALIDE)
âœ… Anthropic: sk-ant-****wxyz (VALIDE)
âœ… CORS configurÃ© pour: https://yourapp.com
ğŸš€ Serveur dÃ©marrÃ© sur http://localhost:8000
```

### ğŸ“– Documentation Interactive

- **ğŸŒŸ Swagger UI** : `http://localhost:8000/docs` - Interface complÃ¨te et interactive
- **ğŸ“š ReDoc** : `http://localhost:8000/redoc` - Documentation technique dÃ©taillÃ©e
- **ğŸ” Health Check** : `http://localhost:8000/api/health` - Status en temps rÃ©el

### ğŸ§ª Validation des Tests

```bash
# Lancer la suite de tests de sÃ©curitÃ©
pytest tests/test_micro_jalon_4_1_a.py -v

# RÃ©sultat attendu
âœ… 9/9 tests passÃ©s - SÃ©curitÃ© validÃ©e
```

## ğŸ¯ Fournisseurs LLM SupportÃ©s

### Configuration Multi-Provider ComplÃ¨te

| Fournisseur | ModÃ¨les SupportÃ©s | CapacitÃ©s | Validation |
|-------------|-------------------|-----------|------------|
| **ğŸ¤– OpenAI** | GPT-3.5-turbo, GPT-4, GPT-4o, O1-preview | Chat, Function Calling, Reasoning | âœ… sk-[48+ chars] |
| **ğŸ§  Anthropic** | Claude 3.5 Sonnet, Claude 3.5 Haiku | Chat, Reasoning, Long Context | âœ… sk-ant-api03-[95+ chars] |
| **ğŸŒŸ Google Gemini** | Gemini 1.5 Pro, Gemini 1.5 Flash | Chat, Vision, Code Generation | âœ… AIza[33+ chars] |
| **ğŸš€ Mistral AI** | Mistral Large, Mistral Small | Chat, Function Calling | âœ… [32 chars] |
| **âš¡ Grok (xAI)** | Grok-3-latest | Chat, Real-time Data | âœ… xai-[40+ chars] |
| **ğŸ‰ Qwen/DashScope** | Qwen-max, Qwen-turbo | Chat, Chinese Language | âœ… sk-[40+ chars] |
| **ğŸ”¥ DeepSeek** | DeepSeek-chat, DeepSeek-coder | Chat, Code Generation | âœ… sk-[40+ chars] |
| **ğŸŒ™ Kimi K2** | Moonshot-v1-128k | Chat, Long Context | âœ… sk-[40+ chars] |

### ğŸ›¡ï¸ Validation Automatique

Chaque adapter vÃ©rifie automatiquement :
- **Format de clÃ©** selon les patterns officiels
- **ConnectivitÃ©** au service provider
- **Masquage sÃ©curisÃ©** dans les logs
- **Gestion d'erreurs** sans exposition de secrets

## ğŸ”Œ API Endpoints Complets

### 1. ğŸ¥ Health Check Global

```http
GET /api/health
```

**RÃ©ponse :**
```json
{
  "status": "healthy",
  "timestamp": "2024-01-01T12:00:00Z",
  "version": "1.0.0",
  "providers_status": {
    "openai": true,
    "anthropic": true,
    "gemini": false,
    "mistral": true
  }
}
```

### 2. ğŸ“‹ Liste des Providers Disponibles

```http
GET /api/providers
```

**RÃ©ponse :**
```json
{
  "providers": [
    {
      "name": "openai",
      "models": ["gpt-3.5-turbo", "gpt-4", "gpt-4o", "o1-preview"],
      "is_healthy": true,
      "capabilities": ["chat", "completion", "function_calling"]
    },
    {
      "name": "anthropic", 
      "models": ["claude-3-5-sonnet-20241022", "claude-3-5-haiku-20241022"],
      "is_healthy": true,
      "capabilities": ["chat", "completion", "reasoning"]
    }
  ]
}
```

### 3. ğŸ†• CrÃ©ation de Session

```http
POST /api/sessions
```

**Corps de la requÃªte :**
```json
{
  "user_id": "user_123",
  "metadata": {
    "context": "Support technique",
    "language": "fr"
  }
}
```

**RÃ©ponse :**
```json
{
  "session_id": "sess_abc123def456",
  "created_at": "2024-01-01T12:00:00Z",
  "status": "active",
  "message_count": 0,
  "summary": null
}
```

### 4. ğŸ¯ Orchestration avec Session

```http
POST /api/orchestrate
```

**Corps de la requÃªte :**
```json
{
  "message": "Explique-moi l'intelligence artificielle en termes simples",
  "agent_config": {
    "provider": "anthropic",
    "model": "claude-3-5-sonnet-20241022",
    "temperature": 0.7,
    "max_tokens": 1000
  },
  "session_id": "sess_abc123def456"
}
```

**RÃ©ponse :**
```json
{
  "response": "L'intelligence artificielle est comme donner Ã  un ordinateur la capacitÃ© de \"rÃ©flÃ©chir\" et d'apprendre...",
  "agent_used": "anthropic",
  "model_used": "claude-3-5-sonnet-20241022",
  "session_id": "sess_abc123def456",
  "message_count": 1,
  "timestamp": "2024-01-01T12:00:00Z",
  "execution_time": 2.34,
  "metadata": {
    "tokens_used": 456,
    "cost_estimate": 0.023,
    "was_summarized": false
  }
}
```

### 5. ğŸ“Š MÃ©triques de Session

```http
GET /api/sessions/{session_id}/metrics
```

**RÃ©ponse :**
```json
{
  "session_id": "sess_abc123def456",
  "message_count": 15,
  "providers_used": ["openai", "anthropic", "gemini"],
  "total_tokens": 12500,
  "total_cost": 1.25,
  "average_response_time": 1.8,
  "last_summary_at": "2024-01-01T11:30:00Z",
  "created_at": "2024-01-01T10:00:00Z"
}
```

### 6. ğŸ“œ Historique de Session

```http
GET /api/sessions/{session_id}/history?limit=10&offset=0
```

**RÃ©ponse :**
```json
{
  "session_id": "sess_abc123def456",
  "messages": [
    {
      "id": "msg_001",
      "role": "user",
      "content": "Explique-moi l'IA",
      "timestamp": "2024-01-01T10:05:00Z"
    },
    {
      "id": "msg_002", 
      "role": "assistant",
      "content": "L'intelligence artificielle...",
      "provider": "anthropic",
      "model": "claude-3-5-sonnet-20241022",
      "timestamp": "2024-01-01T10:05:02Z"
    }
  ],
  "summary": "Discussion sur les concepts de base de l'intelligence artificielle...",
  "has_more": true
}
```

## ğŸ® Exemples d'Usage AvancÃ©s

### Scenario 1: Conversation Multi-Provider

```python
import requests

base_url = "http://localhost:8000/api"

# 1. CrÃ©er une session
session = requests.post(f"{base_url}/sessions", json={
    "user_id": "data_scientist_01",
    "metadata": {"project": "ML Pipeline"}
}).json()

session_id = session["session_id"]

# 2. Question avec GPT-4
response1 = requests.post(f"{base_url}/orchestrate", json={
    "message": "Aide-moi Ã  concevoir un pipeline ML pour la classification d'images",
    "agent_config": {
        "provider": "openai",
        "model": "gpt-4",
        "temperature": 0.3
    },
    "session_id": session_id
}).json()

# 3. Approfondissement avec Claude
response2 = requests.post(f"{base_url}/orchestrate", json={
    "message": "Peux-tu dÃ©tailler les Ã©tapes de prÃ©paration des donnÃ©es?",
    "agent_config": {
        "provider": "anthropic", 
        "model": "claude-3-5-sonnet-20241022",
        "temperature": 0.5
    },
    "session_id": session_id
}).json()

# 4. Code avec DeepSeek
response3 = requests.post(f"{base_url}/orchestrate", json={
    "message": "Ã‰cris-moi le code Python pour implÃ©menter ce pipeline",
    "agent_config": {
        "provider": "deepseek",
        "model": "deepseek-chat",
        "temperature": 0.1
    },
    "session_id": session_id
}).json()
```

### Scenario 2: Session avec RÃ©sumÃ© Automatique

```python
# Configuration d'une session longue qui dÃ©clenche le rÃ©sumÃ© automatique
for i in range(25):  # DÃ©passe le seuil de 20 messages
    response = requests.post(f"{base_url}/orchestrate", json={
        "message": f"Question {i+1} sur l'apprentissage machine",
        "agent_config": {"provider": "gemini", "model": "gemini-1.5-pro"},
        "session_id": session_id
    }).json()
    
    if response.get("metadata", {}).get("was_summarized"):
        print(f"âœ… RÃ©sumÃ© automatique dÃ©clenchÃ© au message {i+1}")
        break
```

### Scenario 3: Monitoring de Performance

```python
# Surveiller les performances de tous les providers
providers = requests.get(f"{base_url}/providers").json()["providers"]

for provider in providers:
    if provider["is_healthy"]:
        # Test de latence
        start_time = time.time()
        response = requests.post(f"{base_url}/orchestrate", json={
            "message": "Test de performance",
            "agent_config": {"provider": provider["name"]},
            "session_id": session_id
        })
        latency = time.time() - start_time
        print(f"{provider['name']}: {latency:.2f}s")
```

## ğŸ›¡ï¸ SÃ©curitÃ© & Bonnes Pratiques

### Configuration de Production

```python
# main.py - Configuration sÃ©curisÃ©e
app.add_middleware(
    CORSMiddleware,
    allow_origins=["https://votre-domaine.com"],  # âš ï¸ Jamais "*" en prod
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE"],
    allow_headers=["Authorization", "Content-Type"],
)

# Headers de sÃ©curitÃ© renforcÃ©s
app.add_middleware(SecurityHeadersMiddleware)
```

### Variables d'Environnement SÃ©curisÃ©es

```bash
# ğŸ”’ Bonnes pratiques pour les API keys

# âœ… Utiliser un gestionnaire de secrets (AWS Secrets Manager, Azure Key Vault)
# âœ… Rotation rÃ©guliÃ¨re des clÃ©s
# âœ… Monitoring des usages
# âœ… Restrictions par IP si possible

# Format de validation automatique
OPENAI_API_KEY=sk-[a-zA-Z0-9]{48}
ANTHROPIC_API_KEY=sk-ant-api03-[a-zA-Z0-9-_]{95}
```

### Monitoring de SÃ©curitÃ©

```python
# Alertes de sÃ©curitÃ© configurables
SECURITY_ALERTS = {
    "max_requests_per_minute": 100,
    "suspicious_patterns": ["admin", "root", "../"],
    "blocked_countries": ["XX", "YY"],
    "rate_limit_per_session": 50
}
```

## ğŸ“Š MÃ©triques & Performance

### Dashboard de Monitoring

```python
# MÃ©triques temps rÃ©el disponibles via /api/metrics
{
    "system": {
        "uptime": "5d 12h 34m",
        "requests_total": 15420,
        "errors_rate": 0.02
    },
    "providers": {
        "openai": {"requests": 5420, "avg_latency": 1.2, "success_rate": 0.99},
        "anthropic": {"requests": 4100, "avg_latency": 1.8, "success_rate": 0.98},
        "gemini": {"requests": 3200, "avg_latency": 2.1, "success_rate": 0.97}
    },
    "sessions": {
        "active": 142,
        "total_created": 1520,
        "avg_duration": "00:23:45"
    }
}
```

## ğŸ§ª Tests Complets

### Suite de Tests AutomatisÃ©s

```bash
# Tests complets avec couverture
python -m pytest tests/ --cov=src --cov-report=html

# Tests par catÃ©gorie
python -m pytest tests/test_session_management.py  # Sessions
python -m pytest tests/test_llm_providers.py       # Providers
python -m pytest tests/test_security.py           # SÃ©curitÃ©
python -m pytest tests/test_performance.py        # Performance

# Tests d'intÃ©gration E2E
python -m pytest tests/test_integration_e2e.py -v
```

### RÃ©sultats de Tests (Jalon 3.5)

```
âœ… 6/6 tests passÃ©s (100%)
â”œâ”€â”€ test_session_creation_and_retrieval âœ…
â”œâ”€â”€ test_orchestration_with_session âœ…  
â”œâ”€â”€ test_session_persistence âœ…
â”œâ”€â”€ test_automatic_summarization âœ…
â”œâ”€â”€ test_session_metrics_calculation âœ…
â””â”€â”€ test_session_history_retrieval âœ…

Coverage: 94% (target: >90%)
```

## ğŸš€ DÃ©ploiement Production

### Docker ContainerisÃ©

```dockerfile
FROM python:3.11-slim

# SÃ©curitÃ© renforcÃ©e
RUN useradd -m -u 1000 appuser
WORKDIR /app

# Installation optimisÃ©e
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Code application
COPY --chown=appuser:appuser . .
USER appuser

# Health check intÃ©grÃ©
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/api/health || exit 1

EXPOSE 8000
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "4"]
```

### Kubernetes Deployment

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: orchestrator-agent
spec:
  replicas: 3
  selector:
    matchLabels:
      app: orchestrator-agent
  template:
    metadata:
      labels:
        app: orchestrator-agent
    spec:
      containers:
      - name: api
        image: orchestrator-agent:latest
        ports:
        - containerPort: 8000
        env:
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: llm-secrets
              key: openai
        resources:
          limits:
            memory: "1Gi"
            cpu: "500m"
          requests:
            memory: "512Mi"
            cpu: "250m"
        livenessProbe:
          httpGet:
            path: /api/health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
```

## ğŸ›¡ï¸ SÃ©curitÃ© Enterprise (Micro-Jalon 4.1-A âœ…)

### Validations de SÃ©curitÃ© Automatiques

**âœ… Configuration CORS SÃ©curisÃ©e :**
- DÃ©veloppement : AccÃ¨s flexible pour dÃ©veloppement local
- Staging : Domaines de staging spÃ©cifiques 
- Production : **Domaines stricts obligatoires** (`CORS_ALLOWED_ORIGINS`)

**âœ… Validation des ClÃ©s API :**
- **Patterns stricts** par fournisseur (8 formats validÃ©s)
- **Masquage automatique** dans logs et erreurs
- **Ã‰chec de dÃ©marrage** si clÃ©s invalides
- **Gestion centralisÃ©e** via `SecureAPIKeyHandler`

**âœ… Standards de SÃ©curitÃ© :**
- Headers sÃ©curisÃ©s (CORS, CSP, etc.)
- Logging sÃ©curisÃ© sans exposition de secrets
- Validation au runtime de toutes les configurations
- Tests automatisÃ©s de sÃ©curitÃ© (9/9 tests âœ…)

### Rapports de Validation

Consultez le rapport complet : [VALIDATION_MICRO_JALON_4_1_A.md](./docs/VALIDATION_MICRO_JALON_4_1_A.md)

## ğŸ§ª Tests et QualitÃ©

### Suite de Tests ComplÃ¨te

```bash
# Tests de sÃ©curitÃ© (Micro-Jalon 4.1-A)
pytest tests/test_micro_jalon_4_1_a.py -v
# âœ… 9/9 tests passÃ©s - SÃ©curitÃ© validÃ©e

# Tests d'intÃ©gration (Jalon 3.5)
pytest tests/test_integration_e2e.py -v
# âœ… 6/6 tests passÃ©s - FonctionnalitÃ©s validÃ©es

# Tests complets
pytest tests/ -v --cov=src
# Coverage: >90%
```

### MÃ©triques de QualitÃ©

| Aspect | Score | Status |
|--------|--------|---------|
| **SÃ©curitÃ©** | 100% | âœ… Production Ready |
| **Couverture Tests** | >90% | âœ… Excellent |
| **Performance** | <500ms | âœ… OptimisÃ© |
| **Documentation** | 100% | âœ… ComplÃ¨te |

## ğŸš€ DÃ©ploiement Production

### ğŸ“¦ Option 1: DÃ©ploiement Direct

```bash
# Configuration production
export ENVIRONMENT=production
export CORS_ALLOWED_ORIGINS=https://yourapp.com,https://admin.yourapp.com

# DÃ©marrage production
uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4
```

### ğŸ³ Option 2: Docker (RecommandÃ©)

```dockerfile
FROM python:3.11-slim

# Configuration sÃ©curisÃ©e
RUN useradd -m -u 1000 appuser
WORKDIR /app

# Installation optimisÃ©e
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Code application
COPY --chown=appuser:appuser . .
USER appuser

# Health check intÃ©grÃ©
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/api/health || exit 1

EXPOSE 8000
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "4"]
```

### â˜¸ï¸ Option 3: Kubernetes

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: orchestrator-agent
spec:
  replicas: 3
  selector:
    matchLabels:
      app: orchestrator-agent
  template:
    metadata:
      labels:
        app: orchestrator-agent
    spec:
      containers:
      - name: orchestrator-agent
        image: orchestrator-agent:latest
        ports:
        - containerPort: 8000
        env:
        - name: ENVIRONMENT
          value: "production"
        - name: CORS_ALLOWED_ORIGINS
          valueFrom:
            secretKeyRef:
              name: orchestrator-secrets
              key: cors-origins
        livenessProbe:
          httpGet:
            path: /api/health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
```

## ğŸ“Š Monitoring et ObservabilitÃ©

### Health Checks IntÃ©grÃ©s

```bash
# Status global de santÃ©
curl http://localhost:8000/api/health

# Status dÃ©taillÃ© des providers
curl http://localhost:8000/api/providers
```

### MÃ©triques Disponibles

- **Performance** : Temps de rÃ©ponse par provider
- **Usage** : Utilisation par modÃ¨le et utilisateur  
- **SantÃ©** : Status de connectivitÃ© en temps rÃ©el
- **SÃ©curitÃ©** : Tentatives d'accÃ¨s, erreurs d'authentification

## ğŸ”„ Roadmap et Jalons

### âœ… Jalons ComplÃ©tÃ©s

- **âœ… Jalon 3.5** : Sessions persistantes et mÃ©moire automatique
- **âœ… Micro-Jalon 4.1-A** : SÃ©curitÃ© enterprise (CORS + API Keys)

### ğŸš€ Jalons Suivants

- **ğŸ”„ Jalon 4.1-B** : ObservabilitÃ© et monitoring avancÃ©
- **ğŸ“‹ Jalon 4.2** : Gestion avancÃ©e des utilisateurs
- **âš¡ Jalon 5.0** : Optimisations performance et cache

## ğŸ“š Documentation ComplÃ¨te

- **[VALIDATION_MICRO_JALON_4_1_A.md](./docs/VALIDATION_MICRO_JALON_4_1_A.md)** : Rapport de sÃ©curitÃ© complet
- **[SECURITY.md](./docs/SECURITY.md)** : Guide de sÃ©curitÃ© dÃ©taillÃ©
- **[MONITORING.md](./docs/MONITORING.md)** : Guide de monitoring
- **[EXAMPLES.md](./docs/EXAMPLES.md)** : Exemples d'utilisation
- **[API Docs](http://localhost:8000/docs)** : Documentation interactive

## ğŸ¤ Contribution et Support

### DÃ©veloppement Local

```bash
# Setup dÃ©veloppement
git clone https://github.com/sylvainbonnecarrere/A-IR-OB1.git
cd A-IR-OB1
python -m venv .venv
.venv\Scripts\activate
pip install -r requirements.txt

# Tests de dÃ©veloppement
pytest tests/ -v

# Linting et formatage
black src/
flake8 src/
```

### Architecture Contributions

Cette plateforme suit l'**Architecture Hexagonale** avec sÃ©paration claire :
- **API Layer** : Endpoints REST
- **Domain Layer** : Logique mÃ©tier 
- **Infrastructure Layer** : Adapters et intÃ©grations externes

**Principes SOLID respectÃ©s** pour une maintenance optimale.

---

## ğŸ‰ Conclusion

L'**Orchestrator Agent** est une plateforme **Production-Ready** qui combine :
- âœ… **SÃ©curitÃ© enterprise** validÃ©e et testÃ©e
- âœ… **8 fournisseurs LLM** avec orchestration intelligente
- âœ… **Architecture hexagonale** maintenable et extensible
- âœ… **Documentation complÃ¨te** et tests automatisÃ©s

**PrÃªt pour le dÃ©ploiement en production** avec validation de sÃ©curitÃ© complÃ¨te.

---

[![GitHub](https://img.shields.io/badge/GitHub-A--IR--OB1-blue?logo=github)](https://github.com/sylvainbonnecarrere/A-IR-OB1)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](./LICENSE)
[![Security](https://img.shields.io/badge/Security-Enterprise%20Ready-green.svg)](./docs/VALIDATION_MICRO_JALON_4_1_A.md)
            prompt=prompt,
            **kwargs
        )
        return response.content
    
    def is_healthy(self) -> bool:
        return self.client is not None and self.api_key is not None
    
    def get_models(self) -> List[str]:
        return ["nouveau-model-v1", "nouveau-model-v2"]

# 2. Enregistrer dans la factory
# src/domain/llm_service_factory.py
def _register_providers(self):
    providers = {
        # ... providers existants
        "nouveau": NouveauProviderAdapter
    }

# 3. Ajouter les tests
# tests/test_nouveau_provider.py
def test_nouveau_provider_integration():
    adapter = NouveauProviderAdapter()
    assert adapter.is_healthy() == (adapter.api_key is not None)
```

### Standards de DÃ©veloppement

- **Code Style** : Black + Flake8
- **Type Hints** : mypy strict
- **Docstrings** : Google format
- **Tests** : pytest + coverage >90%
- **CI/CD** : GitHub Actions
- **Security** : bandit + safety

---

## ğŸ‰ Conclusion

L'**Orchestrator Agent** est une plateforme **Production-Ready** qui combine :
- âœ… **SÃ©curitÃ© enterprise** validÃ©e et testÃ©e
- âœ… **8 fournisseurs LLM** avec orchestration intelligente
- âœ… **Architecture hexagonale** maintenable et extensible
- âœ… **Documentation complÃ¨te** et tests automatisÃ©s

**PrÃªt pour le dÃ©ploiement en production** avec validation de sÃ©curitÃ© complÃ¨te.

---

[![GitHub](https://img.shields.io/badge/GitHub-A--IR--OB1-blue?logo=github)](https://github.com/sylvainbonnecarrere/A-IR-OB1)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](./LICENSE)
[![Security](https://img.shields.io/badge/Security-Enterprise%20Ready-green.svg)](./docs/VALIDATION_MICRO_JALON_4_1_A.md)
