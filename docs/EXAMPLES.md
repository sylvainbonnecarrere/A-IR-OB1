# ğŸ® Exemples d'Usage AvancÃ©s - Orchestrator Agent

Ce guide prÃ©sente des scenarios d'usage rÃ©els dÃ©montrant la puissance de la plateforme Orchestrator Agent avec ses **8 fournisseurs LLM**, **sessions persistantes**, et **mÃ©moire automatique**.

## ğŸš€ Scenarios d'Usage Complets

### 1. ğŸ“Š Analyse de DonnÃ©es Multi-Provider

**Objectif :** Analyser un dataset complexe en utilisant les forces spÃ©cifiques de chaque LLM.

```python
import requests
import json
import time
from typing import Dict, Any

class DataAnalysisOrchestrator:
    def __init__(self, base_url: str = "http://localhost:8000/api"):
        self.base_url = base_url
        self.session_id = None
    
    def create_analysis_session(self, dataset_info: Dict[str, Any]) -> str:
        """CrÃ©e une session dÃ©diÃ©e Ã  l'analyse de donnÃ©es"""
        response = requests.post(f"{self.base_url}/sessions", json={
            "user_id": "data_analyst_01",
            "metadata": {
                "project": "Data Analysis",
                "dataset": dataset_info["name"],
                "size": dataset_info["size"],
                "type": dataset_info["type"]
            }
        })
        self.session_id = response.json()["session_id"]
        print(f"âœ… Session crÃ©Ã©e: {self.session_id}")
        return self.session_id
    
    def statistical_analysis_with_claude(self, data_description: str) -> Dict[str, Any]:
        """Utilise Claude pour l'analyse statistique approfondie"""
        response = requests.post(f"{self.base_url}/orchestrate", json={
            "message": f"""
            Analysez ces donnÃ©es statistiquement: {data_description}
            
            Fournissez:
            1. Statistiques descriptives dÃ©taillÃ©es
            2. Identification des variables clÃ©s
            3. Tests statistiques recommandÃ©s
            4. DÃ©tection d'anomalies potentielles
            5. Recommandations pour l'exploration
            """,
            "agent_config": {
                "provider": "anthropic",
                "model": "claude-3-5-sonnet-20241022",
                "temperature": 0.3,
                "max_tokens": 2000
            },
            "session_id": self.session_id
        })
        
        result = response.json()
        print(f"ğŸ“ˆ Analyse statistique Claude: {result['execution_time']:.2f}s")
        return result
    
    def visualization_code_with_deepseek(self, analysis_results: str) -> Dict[str, Any]:
        """Utilise DeepSeek pour gÃ©nÃ©rer du code de visualisation"""
        response = requests.post(f"{self.base_url}/orchestrate", json={
            "message": f"""
            BasÃ© sur cette analyse statistique: {analysis_results}
            
            GÃ©nÃ©rez du code Python complet pour crÃ©er des visualisations:
            1. Graphiques de distribution
            2. Matrices de corrÃ©lation
            3. Boxplots pour dÃ©tecter les outliers
            4. Graphiques temporels si applicable
            5. Visualisations interactives avec Plotly
            
            Code prÃªt Ã  exÃ©cuter avec commentaires dÃ©taillÃ©s.
            """,
            "agent_config": {
                "provider": "deepseek",
                "model": "deepseek-chat",
                "temperature": 0.1,
                "max_tokens": 3000
            },
            "session_id": self.session_id
        })
        
        result = response.json()
        print(f"ğŸ’» Code visualisation DeepSeek: {result['execution_time']:.2f}s")
        return result
    
    def insights_with_gpt4(self, analysis_context: str) -> Dict[str, Any]:
        """Utilise GPT-4 pour extraire des insights business"""
        response = requests.post(f"{self.base_url}/orchestrate", json={
            "message": f"""
            Contexte d'analyse: {analysis_context}
            
            Fournissez des insights business actionnables:
            1. Tendances principales identifiÃ©es
            2. OpportunitÃ©s d'amÃ©lioration
            3. Risques potentiels
            4. Recommandations stratÃ©giques
            5. Prochaines Ã©tapes suggÃ©rÃ©es
            
            Format: insights clairs et priorisÃ©s.
            """,
            "agent_config": {
                "provider": "openai",
                "model": "gpt-4",
                "temperature": 0.5,
                "max_tokens": 2000
            },
            "session_id": self.session_id
        })
        
        result = response.json()
        print(f"ğŸ’¡ Insights business GPT-4: {result['execution_time']:.2f}s")
        return result
    
    def run_complete_analysis(self, dataset_info: Dict[str, Any]) -> Dict[str, Any]:
        """ExÃ©cute une analyse complÃ¨te multi-provider"""
        print("ğŸš€ DÃ©marrage de l'analyse multi-provider...")
        
        # 1. CrÃ©er la session
        self.create_analysis_session(dataset_info)
        
        # 2. Analyse statistique avec Claude
        data_description = f"Dataset: {dataset_info['description']}"
        statistical_analysis = self.statistical_analysis_with_claude(data_description)
        
        # 3. GÃ©nÃ©ration de code avec DeepSeek
        viz_code = self.visualization_code_with_deepseek(
            statistical_analysis['response'][:1000]  # RÃ©sumÃ© pour le contexte
        )
        
        # 4. Insights business avec GPT-4
        business_insights = self.insights_with_gpt4(
            f"Analyse: {statistical_analysis['response'][:500]}"
        )
        
        # 5. RÃ©cupÃ©rer les mÃ©triques de session
        metrics_response = requests.get(f"{self.base_url}/sessions/{self.session_id}/metrics")
        session_metrics = metrics_response.json()
        
        return {
            "session_id": self.session_id,
            "statistical_analysis": statistical_analysis,
            "visualization_code": viz_code,
            "business_insights": business_insights,
            "session_metrics": session_metrics,
            "providers_used": ["anthropic", "deepseek", "openai"],
            "total_execution_time": (
                statistical_analysis['execution_time'] + 
                viz_code['execution_time'] + 
                business_insights['execution_time']
            )
        }

# Exemple d'utilisation
if __name__ == "__main__":
    orchestrator = DataAnalysisOrchestrator()
    
    dataset_info = {
        "name": "Customer Behavior Analysis",
        "size": "50,000 records",
        "type": "Time series + Demographics",
        "description": """
        Dataset contenant 50,000 enregistrements de comportement client avec:
        - DonnÃ©es dÃ©mographiques (Ã¢ge, localisation, revenus)
        - Historique d'achats (montants, frÃ©quence, catÃ©gories)
        - DonnÃ©es temporelles (5 annÃ©es)
        - MÃ©triques d'engagement (clicks, temps sur site, conversions)
        """
    }
    
    results = orchestrator.run_complete_analysis(dataset_info)
    
    print("\nğŸ“Š RÃ‰SULTATS DE L'ANALYSE MULTI-PROVIDER")
    print("=" * 50)
    print(f"Session ID: {results['session_id']}")
    print(f"Providers utilisÃ©s: {', '.join(results['providers_used'])}")
    print(f"Temps total: {results['total_execution_time']:.2f}s")
    print(f"Messages Ã©changÃ©s: {results['session_metrics']['message_count']}")
    print(f"CoÃ»t estimÃ©: ${results['session_metrics']['total_cost']:.4f}")
```

### 2. ğŸ“ Tuteur IA Adaptatif Multi-Niveau

**Objectif :** CrÃ©er un systÃ¨me de tutorat qui s'adapte au niveau de l'utilisateur en utilisant diffÃ©rents LLMs.

```python
class AdaptiveTutorOrchestrator:
    def __init__(self, base_url: str = "http://localhost:8000/api"):
        self.base_url = base_url
        self.session_id = None
        self.student_level = "beginner"  # beginner, intermediate, advanced
        self.subject = None
    
    def start_tutoring_session(self, student_info: Dict[str, Any]) -> str:
        """DÃ©marre une session de tutorat personnalisÃ©e"""
        response = requests.post(f"{self.base_url}/sessions", json={
            "user_id": f"student_{student_info['id']}",
            "metadata": {
                "type": "tutoring",
                "subject": student_info["subject"],
                "level": student_info["level"],
                "learning_style": student_info.get("learning_style", "visual"),
                "goals": student_info.get("goals", [])
            }
        })
        
        self.session_id = response.json()["session_id"]
        self.student_level = student_info["level"]
        self.subject = student_info["subject"]
        
        print(f"ğŸ“ Session de tutorat crÃ©Ã©e: {self.session_id}")
        return self.session_id
    
    def assess_student_level(self, question: str) -> Dict[str, Any]:
        """Utilise Gemini pour Ã©valuer le niveau de l'Ã©tudiant"""
        response = requests.post(f"{self.base_url}/orchestrate", json={
            "message": f"""
            Question de l'Ã©tudiant: "{question}"
            Sujet: {self.subject}
            
            Analysez cette question pour dÃ©terminer:
            1. Niveau de comprÃ©hension apparent (dÃ©butant/intermÃ©diaire/avancÃ©)
            2. Concepts sous-jacents nÃ©cessaires
            3. Lacunes potentielles identifiÃ©es
            4. Approche pÃ©dagogique recommandÃ©e
            5. PrÃ©requis manquants Ã©ventuels
            
            Format JSON avec Ã©valuation dÃ©taillÃ©e.
            """,
            "agent_config": {
                "provider": "gemini",
                "model": "gemini-1.5-pro",
                "temperature": 0.4,
                "max_tokens": 1500
            },
            "session_id": self.session_id
        })
        
        result = response.json()
        print(f"ğŸ“Š Ã‰valuation niveau Gemini: {result['execution_time']:.2f}s")
        return result
    
    def provide_explanation(self, question: str, level_assessment: str) -> Dict[str, Any]:
        """Utilise Claude pour fournir une explication adaptÃ©e au niveau"""
        provider_by_level = {
            "beginner": ("anthropic", "claude-3-5-haiku-20241022"),
            "intermediate": ("anthropic", "claude-3-5-sonnet-20241022"),
            "advanced": ("openai", "gpt-4")
        }
        
        provider, model = provider_by_level.get(self.student_level, ("anthropic", "claude-3-5-sonnet-20241022"))
        
        response = requests.post(f"{self.base_url}/orchestrate", json={
            "message": f"""
            Question de l'Ã©tudiant: "{question}"
            Ã‰valuation du niveau: {level_assessment}
            Niveau Ã©tudiant: {self.student_level}
            Sujet: {self.subject}
            
            Fournissez une explication adaptÃ©e au niveau {self.student_level}:
            
            Pour niveau dÃ©butant:
            - Langage simple et accessible
            - Analogies du quotidien
            - Ã‰tapes trÃ¨s dÃ©taillÃ©es
            - Exemples concrets
            
            Pour niveau intermÃ©diaire:
            - Terminologie appropriÃ©e
            - Liens avec concepts connexes
            - Exemples pratiques
            - Questions de rÃ©flexion
            
            Pour niveau avancÃ©:
            - Analyse approfondie
            - Nuances et cas particuliers
            - RÃ©fÃ©rences thÃ©oriques
            - DÃ©fis intellectuels
            
            Incluez toujours des exercices pratiques adaptÃ©s.
            """,
            "agent_config": {
                "provider": provider,
                "model": model,
                "temperature": 0.6,
                "max_tokens": 2500
            },
            "session_id": self.session_id
        })
        
        result = response.json()
        print(f"ğŸ“š Explication {provider}: {result['execution_time']:.2f}s")
        return result
    
    def generate_practice_exercises(self, topic: str, difficulty: str) -> Dict[str, Any]:
        """Utilise Mistral pour gÃ©nÃ©rer des exercices pratiques"""
        response = requests.post(f"{self.base_url}/orchestrate", json={
            "message": f"""
            Sujet: {topic}
            Niveau de difficultÃ©: {difficulty}
            Niveau Ã©tudiant: {self.student_level}
            
            GÃ©nÃ©rez 5 exercices pratiques progressifs:
            
            1. Exercice de comprÃ©hension (QCM)
            2. Exercice d'application directe
            3. Exercice de rÃ©solution de problÃ¨me
            4. Exercice crÃ©atif/synthÃ¨se
            5. Exercice de transfert de compÃ©tences
            
            Pour chaque exercice:
            - Ã‰noncÃ© clair
            - Solution dÃ©taillÃ©e
            - CritÃ¨res d'Ã©valuation
            - Conseils si difficultÃ©
            - Temps estimÃ©
            
            Format structurÃ© pour faciliter la pratique.
            """,
            "agent_config": {
                "provider": "mistral",
                "model": "mistral-large-latest",
                "temperature": 0.7,
                "max_tokens": 3000
            },
            "session_id": self.session_id
        })
        
        result = response.json()
        print(f"ğŸ“ Exercices Mistral: {result['execution_time']:.2f}s")
        return result
    
    def provide_feedback(self, student_answer: str, correct_answer: str) -> Dict[str, Any]:
        """Utilise Qwen pour fournir un feedback constructif"""
        response = requests.post(f"{self.base_url}/orchestrate", json={
            "message": f"""
            RÃ©ponse de l'Ã©tudiant: "{student_answer}"
            RÃ©ponse correcte: "{correct_answer}"
            Niveau Ã©tudiant: {self.student_level}
            
            Fournissez un feedback constructif et encourageant:
            
            1. Points positifs identifiÃ©s
            2. Erreurs spÃ©cifiques avec explications
            3. Suggestions d'amÃ©lioration concrÃ¨tes
            4. Ressources complÃ©mentaires recommandÃ©es
            5. Encouragements personnalisÃ©s
            6. Prochaines Ã©tapes suggÃ©rÃ©es
            
            Ton bienveillant et motivant, adaptÃ© au niveau.
            """,
            "agent_config": {
                "provider": "qwen",
                "model": "qwen-turbo",
                "temperature": 0.5,
                "max_tokens": 1500
            },
            "session_id": self.session_id
        })
        
        result = response.json()
        print(f"ğŸ’¬ Feedback Qwen: {result['execution_time']:.2f}s")
        return result
    
    def run_tutoring_session(self, student_info: Dict[str, Any], 
                           question: str, student_answer: str = None) -> Dict[str, Any]:
        """ExÃ©cute une session complÃ¨te de tutorat adaptatif"""
        print("ğŸ“ DÃ©marrage du tutorat adaptatif...")
        
        # 1. CrÃ©er la session
        self.start_tutoring_session(student_info)
        
        # 2. Ã‰valuer le niveau
        level_assessment = self.assess_student_level(question)
        
        # 3. Fournir l'explication adaptÃ©e
        explanation = self.provide_explanation(question, level_assessment['response'][:500])
        
        # 4. GÃ©nÃ©rer des exercices
        exercises = self.generate_practice_exercises(
            topic=self.subject,
            difficulty=self.student_level
        )
        
        # 5. Feedback si rÃ©ponse fournie
        feedback = None
        if student_answer:
            feedback = self.provide_feedback(
                student_answer, 
                "RÃ©ponse modÃ¨le basÃ©e sur l'explication fournie"
            )
        
        # 6. MÃ©triques de session
        metrics_response = requests.get(f"{self.base_url}/sessions/{self.session_id}/metrics")
        session_metrics = metrics_response.json()
        
        return {
            "session_id": self.session_id,
            "level_assessment": level_assessment,
            "explanation": explanation,
            "exercises": exercises,
            "feedback": feedback,
            "session_metrics": session_metrics,
            "providers_used": ["gemini", "anthropic", "mistral", "qwen"] if feedback else ["gemini", "anthropic", "mistral"],
            "adaptation_effective": True
        }

# Exemple d'utilisation
if __name__ == "__main__":
    tutor = AdaptiveTutorOrchestrator()
    
    student_info = {
        "id": "12345",
        "name": "Alice Martin",
        "subject": "Programmation Python",
        "level": "intermediate",
        "learning_style": "hands-on",
        "goals": ["MaÃ®triser les classes", "Comprendre les dÃ©corateurs", "Projet web"]
    }
    
    question = "Comment fonctionnent les dÃ©corateurs en Python et Ã  quoi servent-ils ?"
    student_answer = "Les dÃ©corateurs permettent de modifier une fonction sans changer son code directement"
    
    results = tutor.run_tutoring_session(student_info, question, student_answer)
    
    print("\nğŸ“ RÃ‰SULTATS DU TUTORAT ADAPTATIF")
    print("=" * 50)
    print(f"Session ID: {results['session_id']}")
    print(f"Niveau dÃ©tectÃ©: {tutor.student_level}")
    print(f"Providers utilisÃ©s: {', '.join(results['providers_used'])}")
    print(f"Messages Ã©changÃ©s: {results['session_metrics']['message_count']}")
    print(f"Adaptation rÃ©ussie: {results['adaptation_effective']}")
```

### 3. ğŸ¢ Assistant de Veille Technologique

**Objectif :** SystÃ¨me de veille automatisÃ©e combinant plusieurs LLMs pour analyser les tendances tech.

```python
class TechWatchOrchestrator:
    def __init__(self, base_url: str = "http://localhost:8000/api"):
        self.base_url = base_url
        self.session_id = None
        self.tech_domains = []
    
    def start_tech_watch_session(self, watch_config: Dict[str, Any]) -> str:
        """DÃ©marre une session de veille technologique"""
        response = requests.post(f"{self.base_url}/sessions", json={
            "user_id": f"tech_analyst_{watch_config['analyst_id']}",
            "metadata": {
                "type": "tech_watch",
                "domains": watch_config["domains"],
                "frequency": watch_config.get("frequency", "daily"),
                "focus": watch_config.get("focus", "emerging_technologies"),
                "company": watch_config.get("company", "default")
            }
        })
        
        self.session_id = response.json()["session_id"]
        self.tech_domains = watch_config["domains"]
        
        print(f"ğŸ” Session de veille crÃ©Ã©e: {self.session_id}")
        return self.session_id
    
    def analyze_trends_with_gpt4(self, tech_data: str) -> Dict[str, Any]:
        """Utilise GPT-4 pour l'analyse de tendances"""
        response = requests.post(f"{self.base_url}/orchestrate", json={
            "message": f"""
            DonnÃ©es technologiques rÃ©centes: {tech_data}
            Domaines surveillÃ©s: {', '.join(self.tech_domains)}
            
            Analysez les tendances technologiques Ã©mergentes:
            
            1. TENDANCES PRINCIPALES:
               - Technologies en croissance rapide
               - Nouveaux frameworks/outils populaires
               - Ã‰volutions des standards de l'industrie
            
            2. ANALYSE COMPARATIVE:
               - Comparaison avec les trimestres prÃ©cÃ©dents
               - Positionnement vs concurrents
               - Adoption market vs hype
            
            3. IMPACT BUSINESS:
               - OpportunitÃ©s d'innovation
               - Risques de disruption
               - ROI potentiel d'adoption
            
            4. PRÃ‰DICTIONS:
               - Ã‰volution Ã  6-12 mois
               - Technologies Ã  surveiller
               - Obsolescence probable
            
            Format: rapport exÃ©cutif structurÃ© avec donnÃ©es quantifiÃ©es.
            """,
            "agent_config": {
                "provider": "openai",
                "model": "gpt-4",
                "temperature": 0.4,
                "max_tokens": 3000
            },
            "session_id": self.session_id
        })
        
        result = response.json()
        print(f"ğŸ“ˆ Analyse tendances GPT-4: {result['execution_time']:.2f}s")
        return result
    
    def competitive_analysis_with_claude(self, trends_summary: str) -> Dict[str, Any]:
        """Utilise Claude pour l'analyse concurrentielle approfondie"""
        response = requests.post(f"{self.base_url}/orchestrate", json={
            "message": f"""
            RÃ©sumÃ© des tendances identifiÃ©es: {trends_summary}
            
            Effectuez une analyse concurrentielle stratÃ©gique:
            
            1. POSITIONNEMENT CONCURRENTIEL:
               - Leaders technologiques identifiÃ©s
               - StratÃ©gies d'adoption par secteur
               - Avantages/inconvÃ©nients par solution
            
            2. ANALYSE DES GAPS:
               - OpportunitÃ©s non exploitÃ©es
               - Niches technologiques Ã©mergentes
               - Besoins clients non satisfaits
            
            3. RECOMMANDATIONS STRATÃ‰GIQUES:
               - Technologies Ã  adopter en prioritÃ©
               - Partenariats stratÃ©giques suggÃ©rÃ©s
               - Investissements R&D recommandÃ©s
            
            4. PLAN D'ACTION:
               - Timeline d'implÃ©mentation
               - Ressources nÃ©cessaires
               - MÃ©triques de succÃ¨s
            
            Approche analytique rigoureuse avec preuves Ã  l'appui.
            """,
            "agent_config": {
                "provider": "anthropic",
                "model": "claude-3-5-sonnet-20241022",
                "temperature": 0.3,
                "max_tokens": 2500
            },
            "session_id": self.session_id
        })
        
        result = response.json()
        print(f"ğŸ¯ Analyse concurrentielle Claude: {result['execution_time']:.2f}s")
        return result
    
    def technical_deep_dive_with_deepseek(self, tech_focus: str) -> Dict[str, Any]:
        """Utilise DeepSeek pour l'analyse technique approfondie"""
        response = requests.post(f"{self.base_url}/orchestrate", json={
            "message": f"""
            Focus technique: {tech_focus}
            
            Effectuez une analyse technique approfondie:
            
            1. ARCHITECTURE TECHNIQUE:
               - Composants et modules principaux
               - Patterns d'architecture utilisÃ©s
               - IntÃ©grations et APIs disponibles
            
            2. IMPLÃ‰MENTATION:
               - Code samples et exemples pratiques
               - Bonnes pratiques d'implÃ©mentation
               - PiÃ¨ges Ã  Ã©viter et solutions
            
            3. PERFORMANCE ET SCALABILITÃ‰:
               - Benchmarks et mÃ©triques
               - Limites techniques identifiÃ©es
               - Optimisations possibles
            
            4. Ã‰COSYSTÃˆME ET TOOLING:
               - Outils de dÃ©veloppement
               - BibliothÃ¨ques et extensions
               - CommunautÃ© et support
            
            5. MIGRATION ET ADOPTION:
               - StratÃ©gies de migration
               - Coexistence avec l'existant
               - Formation Ã©quipes nÃ©cessaire
            
            Analyse technique dÃ©taillÃ©e avec exemples de code.
            """,
            "agent_config": {
                "provider": "deepseek",
                "model": "deepseek-chat",
                "temperature": 0.2,
                "max_tokens": 3500
            },
            "session_id": self.session_id
        })
        
        result = response.json()
        print(f"ğŸ”§ Analyse technique DeepSeek: {result['execution_time']:.2f}s")
        return result
    
    def market_intelligence_with_gemini(self, analysis_context: str) -> Dict[str, Any]:
        """Utilise Gemini pour l'intelligence marchÃ©"""
        response = requests.post(f"{self.base_url}/orchestrate", json={
            "message": f"""
            Contexte d'analyse: {analysis_context}
            
            Fournissez une intelligence marchÃ© complÃ¨te:
            
            1. SIZING ET VALORISATION:
               - Taille de marchÃ© actuelle et projetÃ©e
               - Segments de croissance principaux
               - Valorisations et investissements rÃ©cents
            
            2. ACTEURS CLÃ‰S:
               - Leaders Ã©tablis et challengers
               - Startups prometteuses Ã  surveiller
               - Consolidations et acquisitions rÃ©centes
            
            3. DYNAMIQUES MARCHÃ‰:
               - Facteurs de croissance identifiÃ©s
               - BarriÃ¨res Ã  l'entrÃ©e
               - Cycles d'adoption par industrie
            
            4. SIGNAUX FAIBLES:
               - Innovations de rupture potentielles
               - Changements rÃ©glementaires impact
               - Shifts comportementaux utilisateurs
            
            5. RECOMMANDATIONS INVESTISSEMENT:
               - PrioritÃ©s d'allocation budget
               - Horizons temporels par technologie
               - StratÃ©gies hedging recommandÃ©es
            
            Intelligence actionnable avec donnÃ©es marchÃ© rÃ©centes.
            """,
            "agent_config": {
                "provider": "gemini",
                "model": "gemini-1.5-pro",
                "temperature": 0.5,
                "max_tokens": 2800
            },
            "session_id": self.session_id
        })
        
        result = response.json()
        print(f"ğŸ“Š Intelligence marchÃ© Gemini: {result['execution_time']:.2f}s")
        return result
    
    def synthesize_insights_with_mistral(self, all_analyses: Dict[str, Any]) -> Dict[str, Any]:
        """Utilise Mistral pour synthÃ©tiser tous les insights"""
        response = requests.post(f"{self.base_url}/orchestrate", json={
            "message": f"""
            Analyses rÃ©alisÃ©es:
            - Tendances: {all_analyses['trends']['response'][:300]}...
            - Concurrence: {all_analyses['competitive']['response'][:300]}...
            - Technique: {all_analyses['technical']['response'][:300]}...
            - MarchÃ©: {all_analyses['market']['response'][:300]}...
            
            SynthÃ©tisez en rapport exÃ©cutif final:
            
            ## EXECUTIVE SUMMARY
            - 3 insights clÃ©s prioritaires
            - Impact business estimÃ©
            - Actions immÃ©diates recommandÃ©es
            
            ## STRATEGIC ROADMAP
            - Phase 1 (0-3 mois): Actions critiques
            - Phase 2 (3-6 mois): DÃ©veloppements stratÃ©giques
            - Phase 3 (6-12 mois): Innovations long terme
            
            ## RISK ASSESSMENT
            - Risques technologiques identifiÃ©s
            - Risques concurrentiels
            - StratÃ©gies de mitigation
            
            ## KPIs DE SUIVI
            - MÃ©triques d'adoption
            - Indicateurs de performance
            - Seuils d'alerte
            
            Format: rapport exÃ©cutif prÃªt pour prÃ©sentation C-level.
            """,
            "agent_config": {
                "provider": "mistral",
                "model": "mistral-large-latest",
                "temperature": 0.4,
                "max_tokens": 2500
            },
            "session_id": self.session_id
        })
        
        result = response.json()
        print(f"ğŸ“‹ SynthÃ¨se finale Mistral: {result['execution_time']:.2f}s")
        return result
    
    def run_complete_tech_watch(self, watch_config: Dict[str, Any], 
                              tech_data: str) -> Dict[str, Any]:
        """ExÃ©cute une veille technologique complÃ¨te"""
        print("ğŸ” DÃ©marrage de la veille technologique complÃ¨te...")
        
        # 1. CrÃ©er la session
        self.start_tech_watch_session(watch_config)
        
        # 2. Analyse des tendances avec GPT-4
        trends_analysis = self.analyze_trends_with_gpt4(tech_data)
        
        # 3. Analyse concurrentielle avec Claude
        competitive_analysis = self.competitive_analysis_with_claude(
            trends_analysis['response'][:800]
        )
        
        # 4. Deep dive technique avec DeepSeek
        technical_analysis = self.technical_deep_dive_with_deepseek(
            watch_config['domains'][0]  # Focus sur le premier domaine
        )
        
        # 5. Intelligence marchÃ© avec Gemini
        market_intelligence = self.market_intelligence_with_gemini(
            f"Trends: {trends_analysis['response'][:400]}... Competitive: {competitive_analysis['response'][:400]}..."
        )
        
        # 6. SynthÃ¨se finale avec Mistral
        all_analyses = {
            'trends': trends_analysis,
            'competitive': competitive_analysis,
            'technical': technical_analysis,
            'market': market_intelligence
        }
        
        final_synthesis = self.synthesize_insights_with_mistral(all_analyses)
        
        # 7. MÃ©triques de session
        metrics_response = requests.get(f"{self.base_url}/sessions/{self.session_id}/metrics")
        session_metrics = metrics_response.json()
        
        return {
            "session_id": self.session_id,
            "trends_analysis": trends_analysis,
            "competitive_analysis": competitive_analysis,
            "technical_analysis": technical_analysis,
            "market_intelligence": market_intelligence,
            "final_synthesis": final_synthesis,
            "session_metrics": session_metrics,
            "providers_used": ["openai", "anthropic", "deepseek", "gemini", "mistral"],
            "total_execution_time": sum([
                trends_analysis['execution_time'],
                competitive_analysis['execution_time'],
                technical_analysis['execution_time'],
                market_intelligence['execution_time'],
                final_synthesis['execution_time']
            ]),
            "domains_analyzed": self.tech_domains
        }

# Exemple d'utilisation
if __name__ == "__main__":
    tech_watch = TechWatchOrchestrator()
    
    watch_config = {
        "analyst_id": "TW_001",
        "domains": ["AI/ML", "Cloud Computing", "Cybersecurity", "DevOps"],
        "frequency": "weekly",
        "focus": "enterprise_adoption",
        "company": "TechCorp Inc."
    }
    
    tech_data = """
    DonnÃ©es rÃ©centes Q4 2024:
    - Adoption massive de l'IA gÃ©nÃ©rative en entreprise (+340%)
    - Croissance des solutions edge computing (+125%)
    - Nouvelles rÃ©gulations cybersÃ©curitÃ© EU/US
    - Kubernetes devient standard de facto (87% adoption)
    - Ã‰mergence des LLMs spÃ©cialisÃ©s par domaine
    - Consolidation marchÃ© cloud providers
    - Zero-trust architecture mainstream
    - Quantum computing: premiers cas d'usage pratiques
    """
    
    results = tech_watch.run_complete_tech_watch(watch_config, tech_data)
    
    print("\nğŸ” RÃ‰SULTATS DE LA VEILLE TECHNOLOGIQUE")
    print("=" * 60)
    print(f"Session ID: {results['session_id']}")
    print(f"Domaines analysÃ©s: {', '.join(results['domains_analyzed'])}")
    print(f"Providers utilisÃ©s: {', '.join(results['providers_used'])}")
    print(f"Temps total d'analyse: {results['total_execution_time']:.2f}s")
    print(f"Messages Ã©changÃ©s: {results['session_metrics']['message_count']}")
    print(f"CoÃ»t total: ${results['session_metrics']['total_cost']:.4f}")
    print(f"Providers sollicitÃ©s: {len(results['session_metrics']['providers_used'])}")
```

### 4. ğŸ“± Assistant de Session Longue avec Auto-Summarization

**Objectif :** DÃ©montrer la gestion automatique de la mÃ©moire et du rÃ©sumÃ© en session longue.

```python
class LongSessionOrchestrator:
    def __init__(self, base_url: str = "http://localhost:8000/api"):
        self.base_url = base_url
        self.session_id = None
        self.message_count = 0
    
    def start_long_session(self, context: str) -> str:
        """DÃ©marre une session longue avec contexte"""
        response = requests.post(f"{self.base_url}/sessions", json={
            "user_id": "long_session_user",
            "metadata": {
                "type": "long_conversation",
                "context": context,
                "auto_summarization": True,
                "summarization_threshold": 10  # RÃ©sumÃ© tous les 10 messages pour la dÃ©mo
            }
        })
        
        self.session_id = response.json()["session_id"]
        print(f"ğŸš€ Session longue crÃ©Ã©e: {self.session_id}")
        return self.session_id
    
    def send_message(self, message: str, provider: str = "openai") -> Dict[str, Any]:
        """Envoie un message dans la session"""
        response = requests.post(f"{self.base_url}/orchestrate", json={
            "message": message,
            "agent_config": {
                "provider": provider,
                "model": "gpt-3.5-turbo" if provider == "openai" else "claude-3-5-haiku-20241022",
                "temperature": 0.7,
                "max_tokens": 1000
            },
            "session_id": self.session_id
        })
        
        result = response.json()
        self.message_count += 1
        
        # VÃ©rifier si un rÃ©sumÃ© a Ã©tÃ© dÃ©clenchÃ©
        was_summarized = result.get('metadata', {}).get('was_summarized', False)
        if was_summarized:
            print(f"ğŸ§  RÃ©sumÃ© automatique dÃ©clenchÃ© au message {self.message_count}")
        
        print(f"ğŸ’¬ Message {self.message_count} ({provider}): {result['execution_time']:.2f}s")
        return result
    
    def demonstrate_auto_summarization(self) -> Dict[str, Any]:
        """DÃ©montre le mÃ©canisme de rÃ©sumÃ© automatique"""
        print("ğŸ“š DÃ©monstration de la summarization automatique...")
        
        # 1. CrÃ©er une session longue
        self.start_long_session("Projet de dÃ©veloppement d'application mobile")
        
        # SÃ©rie de messages qui vont dÃ©clencher la summarization
        messages = [
            ("Bonjour, je travaille sur une app mobile de fitness", "openai"),
            ("Quelles sont les meilleures pratiques UX pour ce type d'app?", "anthropic"),
            ("Comment gÃ©rer l'authentification des utilisateurs?", "openai"),
            ("Quel backend recommandez-vous pour une app fitness?", "gemini"),
            ("Comment implÃ©menter le tracking GPS pour les courses?", "deepseek"),
            ("Quelles APIs utiliser pour les donnÃ©es nutritionnelles?", "mistral"),
            ("Comment optimiser les performances de l'app?", "anthropic"),
            ("Quelle stratÃ©gie de monÃ©tisation adopter?", "openai"),
            ("Comment gÃ©rer les notifications push efficacement?", "qwen"),
            ("Quels tests automatisÃ©s mettre en place?", "openai"),
            # Le 11Ã¨me message devrait dÃ©clencher la summarization
            ("Comment dÃ©ployer l'app sur les stores?", "anthropic"),
            ("AprÃ¨s le rÃ©sumÃ©, continuons avec les mÃ©triques d'usage", "gemini"),
            ("Comment analyser le comportement des utilisateurs?", "openai"),
        ]
        
        responses = []
        summarization_triggered = False
        
        for i, (message, provider) in enumerate(messages, 1):
            print(f"\n--- Message {i} ---")
            response = self.send_message(message, provider)
            responses.append(response)
            
            # DÃ©tecter si la summarization a Ã©tÃ© dÃ©clenchÃ©e
            if response.get('metadata', {}).get('was_summarized', False):
                summarization_triggered = True
                print(f"âœ… RÃ©sumÃ© automatique confirmÃ© au message {i}")
                
                # RÃ©cupÃ©rer l'historique pour voir le rÃ©sumÃ©
                history_response = requests.get(
                    f"{self.base_url}/sessions/{self.session_id}/history?limit=50"
                )
                history = history_response.json()
                
                print(f"ğŸ“ RÃ©sumÃ© gÃ©nÃ©rÃ©: {history.get('summary', 'Aucun rÃ©sumÃ©')[:200]}...")
        
        # MÃ©triques finales
        metrics_response = requests.get(f"{self.base_url}/sessions/{self.session_id}/metrics")
        session_metrics = metrics_response.json()
        
        return {
            "session_id": self.session_id,
            "total_messages": len(responses),
            "summarization_triggered": summarization_triggered,
            "providers_used": list(set(msg[1] for msg in messages)),
            "session_metrics": session_metrics,
            "responses": responses
        }

# Exemple d'utilisation
if __name__ == "__main__":
    long_session = LongSessionOrchestrator()
    
    results = long_session.demonstrate_auto_summarization()
    
    print("\nğŸ“š RÃ‰SULTATS DÃ‰MONSTRATION AUTO-SUMMARIZATION")
    print("=" * 60)
    print(f"Session ID: {results['session_id']}")
    print(f"Messages envoyÃ©s: {results['total_messages']}")
    print(f"RÃ©sumÃ© dÃ©clenchÃ©: {'âœ… Oui' if results['summarization_triggered'] else 'âŒ Non'}")
    print(f"Providers utilisÃ©s: {', '.join(results['providers_used'])}")
    print(f"Message count final: {results['session_metrics']['message_count']}")
    print(f"CoÃ»t total: ${results['session_metrics']['total_cost']:.4f}")
    
    if results['summarization_triggered']:
        print("ğŸ‰ DÃ©monstration rÃ©ussie de la mÃ©moire automatique!")
    else:
        print("âš ï¸ Le seuil de summarization n'a pas Ã©tÃ© atteint dans cette dÃ©mo")
```

## ğŸ¯ ExÃ©cution des Exemples

### PrÃ©requis

```bash
# 1. DÃ©marrer le serveur Orchestrator Agent
python main.py

# 2. Installer les dÃ©pendances pour les exemples
pip install requests

# 3. Configurer les clÃ©s API dans .env
# (Voir ./SECURITY.md pour la configuration complÃ¨te)
```

### Lancement des ScÃ©narios

```python
# ExÃ©cuter tous les exemples
if __name__ == "__main__":
    import asyncio
    
    async def run_all_scenarios():
        """ExÃ©cute tous les scÃ©narios d'usage avancÃ©s"""
        
        print("ğŸš€ LANCEMENT DES SCÃ‰NARIOS AVANCÃ‰S")
        print("=" * 50)
        
        # ScÃ©nario 1: Analyse de donnÃ©es
        print("\n1ï¸âƒ£ Analyse de DonnÃ©es Multi-Provider")
        data_orchestrator = DataAnalysisOrchestrator()
        # ... (code du scÃ©nario)
        
        # ScÃ©nario 2: Tutorat adaptatif
        print("\n2ï¸âƒ£ Tutorat IA Adaptatif")
        tutor = AdaptiveTutorOrchestrator()
        # ... (code du scÃ©nario)
        
        # ScÃ©nario 3: Veille technologique
        print("\n3ï¸âƒ£ Veille Technologique")
        tech_watch = TechWatchOrchestrator()
        # ... (code du scÃ©nario)
        
        # ScÃ©nario 4: Session longue
        print("\n4ï¸âƒ£ Auto-Summarization")
        long_session = LongSessionOrchestrator()
        # ... (code du scÃ©nario)
        
        print("\nâœ… TOUS LES SCÃ‰NARIOS TERMINÃ‰S")
    
    # Lancer les scÃ©narios
    asyncio.run(run_all_scenarios())
```

---

## ğŸ“Š MÃ©triques et Performance

Chaque scÃ©nario gÃ©nÃ¨re des mÃ©triques dÃ©taillÃ©es :

- **Temps d'exÃ©cution** par provider
- **CoÃ»t estimÃ©** par requÃªte
- **Nombre de tokens** utilisÃ©s
- **Taux de succÃ¨s** des requÃªtes
- **Performance comparative** entre providers

## ğŸ¯ Personnalisation

Ces exemples sont entiÃ¨rement personnalisables :

1. **Modifiez les providers** selon vos besoins
2. **Ajustez les paramÃ¨tres** (temperature, max_tokens)
3. **Adaptez les prompts** Ã  votre domaine
4. **Configurez les seuils** de summarization
5. **Personnalisez les mÃ©triques** collectÃ©es

---

> ğŸ® **Ces exemples dÃ©montrent la puissance rÃ©elle de l'Orchestrator Agent** avec ses sessions persistantes, sa mÃ©moire automatique, et son orchestration intelligente de 8 fournisseurs LLM diffÃ©rents.