# üéÆ Exemples d'Usage Avanc√©s - Orchestrator Agent

Ce guide pr√©sente des scenarios d'usage r√©els d√©montrant la puissance de la plateforme Orchestrator Agent avec ses **8 fournisseurs LLM**, **sessions persistantes**, et **m√©moire automatique**.

## üöÄ Scenarios d'Usage Complets

### 1. üìä Analyse de Donn√©es Multi-Provider

**Objectif :** Analyser un dataset complexe en utilisant les forces sp√©cifiques de chaque LLM.

```python
import requests
import json
import time
from typing import Dict, Any

class DataAnalysisOrchestrator:
    def __init__(self, base_url: str = "http://localhost:8000/api"):
        self.base_url = base_url
        self.session_id = None
    
    def create_analysis_session(self, dataset_info: Dict[str, Any]) -> str:
        """Cr√©e une session d√©di√©e √† l'analyse de donn√©es"""
        response = requests.post(f"{self.base_url}/sessions", json={
            "user_id": "data_analyst_01",
            "metadata": {
                "project": "Data Analysis",
                "dataset": dataset_info["name"],
                "size": dataset_info["size"],
                "type": dataset_info["type"]
            }
        })
        self.session_id = response.json()["session_id"]
        print(f"‚úÖ Session cr√©√©e: {self.session_id}")
        return self.session_id
    
    def statistical_analysis_with_claude(self, data_description: str) -> Dict[str, Any]:
        """Utilise Claude pour l'analyse statistique approfondie"""
        response = requests.post(f"{self.base_url}/orchestrate", json={
            "message": f"""
            Analysez ces donn√©es statistiquement: {data_description}
            
            Fournissez:
            1. Statistiques descriptives d√©taill√©es
            2. Identification des variables cl√©s
            3. Tests statistiques recommand√©s
            4. D√©tection d'anomalies potentielles
            5. Recommandations pour l'exploration
            """,
            "agent_config": {
                "provider": "anthropic",
                "model": "claude-3-5-sonnet-20241022",
                "temperature": 0.3,
                "max_tokens": 2000
            },
            "session_id": self.session_id
        })
        
        result = response.json()
        print(f"üìà Analyse statistique Claude: {result['execution_time']:.2f}s")
        return result
    
    def visualization_code_with_deepseek(self, analysis_results: str) -> Dict[str, Any]:
        """Utilise DeepSeek pour g√©n√©rer du code de visualisation"""
        response = requests.post(f"{self.base_url}/orchestrate", json={
            "message": f"""
            Bas√© sur cette analyse statistique: {analysis_results}
            
            G√©n√©rez du code Python complet pour cr√©er des visualisations:
            1. Graphiques de distribution
            2. Matrices de corr√©lation
            3. Boxplots pour d√©tecter les outliers
            4. Graphiques temporels si applicable
            5. Visualisations interactives avec Plotly
            
            Code pr√™t √† ex√©cuter avec commentaires d√©taill√©s.
            """,
            "agent_config": {
                "provider": "deepseek",
                "model": "deepseek-chat",
                "temperature": 0.1,
                "max_tokens": 3000
            },
            "session_id": self.session_id
        })
        
        result = response.json()
        print(f"üíª Code visualisation DeepSeek: {result['execution_time']:.2f}s")
        return result
    
    def insights_with_gpt4(self, analysis_context: str) -> Dict[str, Any]:
        """Utilise GPT-4 pour extraire des insights business"""
        response = requests.post(f"{self.base_url}/orchestrate", json={
            "message": f"""
            Contexte d'analyse: {analysis_context}
            
            Fournissez des insights business actionnables:
            1. Tendances principales identifi√©es
            2. Opportunit√©s d'am√©lioration
            3. Risques potentiels
            4. Recommandations strat√©giques
            5. Prochaines √©tapes sugg√©r√©es
            
            Format: insights clairs et prioris√©s.
            """,
            "agent_config": {
                "provider": "openai",
                "model": "gpt-4",
                "temperature": 0.5,
                "max_tokens": 2000
            },
            "session_id": self.session_id
        })
        
        result = response.json()
        print(f"üí° Insights business GPT-4: {result['execution_time']:.2f}s")
        return result
    
    def run_complete_analysis(self, dataset_info: Dict[str, Any]) -> Dict[str, Any]:
        """Ex√©cute une analyse compl√®te multi-provider"""
        print("üöÄ D√©marrage de l'analyse multi-provider...")
        
        # 1. Cr√©er la session
        self.create_analysis_session(dataset_info)
        
        # 2. Analyse statistique avec Claude
        data_description = f"Dataset: {dataset_info['description']}"
        statistical_analysis = self.statistical_analysis_with_claude(data_description)
        
        # 3. G√©n√©ration de code avec DeepSeek
        viz_code = self.visualization_code_with_deepseek(
            statistical_analysis['response'][:1000]  # R√©sum√© pour le contexte
        )
        
        # 4. Insights business avec GPT-4
        business_insights = self.insights_with_gpt4(
            f"Analyse: {statistical_analysis['response'][:500]}"
        )
        
        # 5. R√©cup√©rer les m√©triques de session
        metrics_response = requests.get(f"{self.base_url}/sessions/{self.session_id}/metrics")
        session_metrics = metrics_response.json()
        
        return {
            "session_id": self.session_id,
            "statistical_analysis": statistical_analysis,
            "visualization_code": viz_code,
            "business_insights": business_insights,
            "session_metrics": session_metrics,
            "providers_used": ["anthropic", "deepseek", "openai"],
            "total_execution_time": (
                statistical_analysis['execution_time'] + 
                viz_code['execution_time'] + 
                business_insights['execution_time']
            )
        }

# Exemple d'utilisation
if __name__ == "__main__":
    orchestrator = DataAnalysisOrchestrator()
    
    dataset_info = {
        "name": "Customer Behavior Analysis",
        "size": "50,000 records",
        "type": "Time series + Demographics",
        "description": """
        Dataset contenant 50,000 enregistrements de comportement client avec:
        - Donn√©es d√©mographiques (√¢ge, localisation, revenus)
        - Historique d'achats (montants, fr√©quence, cat√©gories)
        - Donn√©es temporelles (5 ann√©es)
        - M√©triques d'engagement (clicks, temps sur site, conversions)
        """
    }
    
    results = orchestrator.run_complete_analysis(dataset_info)
    
    print("\nüìä R√âSULTATS DE L'ANALYSE MULTI-PROVIDER")
    print("=" * 50)
    print(f"Session ID: {results['session_id']}")
    print(f"Providers utilis√©s: {', '.join(results['providers_used'])}")
    print(f"Temps total: {results['total_execution_time']:.2f}s")
    print(f"Messages √©chang√©s: {results['session_metrics']['message_count']}")
    print(f"Co√ªt estim√©: ${results['session_metrics']['total_cost']:.4f}")
```

### 2. üéì Tuteur IA Adaptatif Multi-Niveau

**Objectif :** Cr√©er un syst√®me de tutorat qui s'adapte au niveau de l'utilisateur en utilisant diff√©rents LLMs.

```python
class AdaptiveTutorOrchestrator:
    def __init__(self, base_url: str = "http://localhost:8000/api"):
        self.base_url = base_url
        self.session_id = None
        self.student_level = "beginner"  # beginner, intermediate, advanced
        self.subject = None
    
    def start_tutoring_session(self, student_info: Dict[str, Any]) -> str:
        """D√©marre une session de tutorat personnalis√©e"""
        response = requests.post(f"{self.base_url}/sessions", json={
            "user_id": f"student_{student_info['id']}",
            "metadata": {
                "type": "tutoring",
                "subject": student_info["subject"],
                "level": student_info["level"],
                "learning_style": student_info.get("learning_style", "visual"),
                "goals": student_info.get("goals", [])
            }
        })
        
        self.session_id = response.json()["session_id"]
        self.student_level = student_info["level"]
        self.subject = student_info["subject"]
        
        print(f"üéì Session de tutorat cr√©√©e: {self.session_id}")
        return self.session_id
    
    def assess_student_level(self, question: str) -> Dict[str, Any]:
        """Utilise Gemini pour √©valuer le niveau de l'√©tudiant"""
        response = requests.post(f"{self.base_url}/orchestrate", json={
            "message": f"""
            Question de l'√©tudiant: "{question}"
            Sujet: {self.subject}
            
            Analysez cette question pour d√©terminer:
            1. Niveau de compr√©hension apparent (d√©butant/interm√©diaire/avanc√©)
            2. Concepts sous-jacents n√©cessaires
            3. Lacunes potentielles identifi√©es
            4. Approche p√©dagogique recommand√©e
            5. Pr√©requis manquants √©ventuels
            
            Format JSON avec √©valuation d√©taill√©e.
            """,
            "agent_config": {
                "provider": "gemini",
                "model": "gemini-1.5-pro",
                "temperature": 0.4,
                "max_tokens": 1500
            },
            "session_id": self.session_id
        })
        
        result = response.json()
        print(f"üìä √âvaluation niveau Gemini: {result['execution_time']:.2f}s")
        return result
    
    def provide_explanation(self, question: str, level_assessment: str) -> Dict[str, Any]:
        """Utilise Claude pour fournir une explication adapt√©e au niveau"""
        provider_by_level = {
            "beginner": ("anthropic", "claude-3-5-haiku-20241022"),
            "intermediate": ("anthropic", "claude-3-5-sonnet-20241022"),
            "advanced": ("openai", "gpt-4")
        }
        
        provider, model = provider_by_level.get(self.student_level, ("anthropic", "claude-3-5-sonnet-20241022"))
        
        response = requests.post(f"{self.base_url}/orchestrate", json={
            "message": f"""
            Question de l'√©tudiant: "{question}"
            √âvaluation du niveau: {level_assessment}
            Niveau √©tudiant: {self.student_level}
            Sujet: {self.subject}
            
            Fournissez une explication adapt√©e au niveau {self.student_level}:
            
            Pour niveau d√©butant:
            - Langage simple et accessible
            - Analogies du quotidien
            - √âtapes tr√®s d√©taill√©es
            - Exemples concrets
            
            Pour niveau interm√©diaire:
            - Terminologie appropri√©e
            - Liens avec concepts connexes
            - Exemples pratiques
            - Questions de r√©flexion
            
            Pour niveau avanc√©:
            - Analyse approfondie
            - Nuances et cas particuliers
            - R√©f√©rences th√©oriques
            - D√©fis intellectuels
            
            Incluez toujours des exercices pratiques adapt√©s.
            """,
            "agent_config": {
                "provider": provider,
                "model": model,
                "temperature": 0.6,
                "max_tokens": 2500
            },
            "session_id": self.session_id
        })
        
        result = response.json()
        print(f"üìö Explication {provider}: {result['execution_time']:.2f}s")
        return result
    
    def generate_practice_exercises(self, topic: str, difficulty: str) -> Dict[str, Any]:
        """Utilise Mistral pour g√©n√©rer des exercices pratiques"""
        response = requests.post(f"{self.base_url}/orchestrate", json={
            "message": f"""
            Sujet: {topic}
            Niveau de difficult√©: {difficulty}
            Niveau √©tudiant: {self.student_level}
            
            G√©n√©rez 5 exercices pratiques progressifs:
            
            1. Exercice de compr√©hension (QCM)
            2. Exercice d'application directe
            3. Exercice de r√©solution de probl√®me
            4. Exercice cr√©atif/synth√®se
            5. Exercice de transfert de comp√©tences
            
            Pour chaque exercice:
            - √ânonc√© clair
            - Solution d√©taill√©e
            - Crit√®res d'√©valuation
            - Conseils si difficult√©
            - Temps estim√©
            
            Format structur√© pour faciliter la pratique.
            """,
            "agent_config": {
                "provider": "mistral",
                "model": "mistral-large-latest",
                "temperature": 0.7,
                "max_tokens": 3000
            },
            "session_id": self.session_id
        })
        
        result = response.json()
        print(f"üìù Exercices Mistral: {result['execution_time']:.2f}s")
        return result
    
    def provide_feedback(self, student_answer: str, correct_answer: str) -> Dict[str, Any]:
        """Utilise Qwen pour fournir un feedback constructif"""
        response = requests.post(f"{self.base_url}/orchestrate", json={
            "message": f"""
            R√©ponse de l'√©tudiant: "{student_answer}"
            R√©ponse correcte: "{correct_answer}"
            Niveau √©tudiant: {self.student_level}
            
            Fournissez un feedback constructif et encourageant:
            
            1. Points positifs identifi√©s
            2. Erreurs sp√©cifiques avec explications
            3. Suggestions d'am√©lioration concr√®tes
            4. Ressources compl√©mentaires recommand√©es
            5. Encouragements personnalis√©s
            6. Prochaines √©tapes sugg√©r√©es
            
            Ton bienveillant et motivant, adapt√© au niveau.
            """,
            "agent_config": {
                "provider": "qwen",
                "model": "qwen-turbo",
                "temperature": 0.5,
                "max_tokens": 1500
            },
            "session_id": self.session_id
        })
        
        result = response.json()
        print(f"üí¨ Feedback Qwen: {result['execution_time']:.2f}s")
        return result
    
    def run_tutoring_session(self, student_info: Dict[str, Any], 
                           question: str, student_answer: str = None) -> Dict[str, Any]:
        """Ex√©cute une session compl√®te de tutorat adaptatif"""
        print("üéì D√©marrage du tutorat adaptatif...")
        
        # 1. Cr√©er la session
        self.start_tutoring_session(student_info)
        
        # 2. √âvaluer le niveau
        level_assessment = self.assess_student_level(question)
        
        # 3. Fournir l'explication adapt√©e
        explanation = self.provide_explanation(question, level_assessment['response'][:500])
        
        # 4. G√©n√©rer des exercices
        exercises = self.generate_practice_exercises(
            topic=self.subject,
            difficulty=self.student_level
        )
        
        # 5. Feedback si r√©ponse fournie
        feedback = None
        if student_answer:
            feedback = self.provide_feedback(
                student_answer, 
                "R√©ponse mod√®le bas√©e sur l'explication fournie"
            )
        
        # 6. M√©triques de session
        metrics_response = requests.get(f"{self.base_url}/sessions/{self.session_id}/metrics")
        session_metrics = metrics_response.json()
        
        return {
            "session_id": self.session_id,
            "level_assessment": level_assessment,
            "explanation": explanation,
            "exercises": exercises,
            "feedback": feedback,
            "session_metrics": session_metrics,
            "providers_used": ["gemini", "anthropic", "mistral", "qwen"] if feedback else ["gemini", "anthropic", "mistral"],
            "adaptation_effective": True
        }

# Exemple d'utilisation
if __name__ == "__main__":
    tutor = AdaptiveTutorOrchestrator()
    
    student_info = {
        "id": "12345",
        "name": "Alice Martin",
        "subject": "Programmation Python",
        "level": "intermediate",
        "learning_style": "hands-on",
        "goals": ["Ma√Ætriser les classes", "Comprendre les d√©corateurs", "Projet web"]
    }
    
    question = "Comment fonctionnent les d√©corateurs en Python et √† quoi servent-ils ?"
    student_answer = "Les d√©corateurs permettent de modifier une fonction sans changer son code directement"
    
    results = tutor.run_tutoring_session(student_info, question, student_answer)
    
    print("\nüéì R√âSULTATS DU TUTORAT ADAPTATIF")
    print("=" * 50)
    print(f"Session ID: {results['session_id']}")
    print(f"Niveau d√©tect√©: {tutor.student_level}")
    print(f"Providers utilis√©s: {', '.join(results['providers_used'])}")
    print(f"Messages √©chang√©s: {results['session_metrics']['message_count']}")
    print(f"Adaptation r√©ussie: {results['adaptation_effective']}")
```

### 3. üè¢ Assistant de Veille Technologique

**Objectif :** Syst√®me de veille automatis√©e combinant plusieurs LLMs pour analyser les tendances tech.

```python
class TechWatchOrchestrator:
    def __init__(self, base_url: str = "http://localhost:8000/api"):
        self.base_url = base_url
        self.session_id = None
        self.tech_domains = []
    
    def start_tech_watch_session(self, watch_config: Dict[str, Any]) -> str:
        """D√©marre une session de veille technologique"""
        response = requests.post(f"{self.base_url}/sessions", json={
            "user_id": f"tech_analyst_{watch_config['analyst_id']}",
            "metadata": {
                "type": "tech_watch",
                "domains": watch_config["domains"],
                "frequency": watch_config.get("frequency", "daily"),
                "focus": watch_config.get("focus", "emerging_technologies"),
                "company": watch_config.get("company", "default")
            }
        })
        
        self.session_id = response.json()["session_id"]
        self.tech_domains = watch_config["domains"]
        
        print(f"üîç Session de veille cr√©√©e: {self.session_id}")
        return self.session_id
    
    def analyze_trends_with_gpt4(self, tech_data: str) -> Dict[str, Any]:
        """Utilise GPT-4 pour l'analyse de tendances"""
        response = requests.post(f"{self.base_url}/orchestrate", json={
            "message": f"""
            Donn√©es technologiques r√©centes: {tech_data}
            Domaines surveill√©s: {', '.join(self.tech_domains)}
            
            Analysez les tendances technologiques √©mergentes:
            
            1. TENDANCES PRINCIPALES:
               - Technologies en croissance rapide
               - Nouveaux frameworks/outils populaires
               - √âvolutions des standards de l'industrie
            
            2. ANALYSE COMPARATIVE:
               - Comparaison avec les trimestres pr√©c√©dents
               - Positionnement vs concurrents
               - Adoption market vs hype
            
            3. IMPACT BUSINESS:
               - Opportunit√©s d'innovation
               - Risques de disruption
               - ROI potentiel d'adoption
            
            4. PR√âDICTIONS:
               - √âvolution √† 6-12 mois
               - Technologies √† surveiller
               - Obsolescence probable
            
            Format: rapport ex√©cutif structur√© avec donn√©es quantifi√©es.
            """,
            "agent_config": {
                "provider": "openai",
                "model": "gpt-4",
                "temperature": 0.4,
                "max_tokens": 3000
            },
            "session_id": self.session_id
        })
        
        result = response.json()
        print(f"üìà Analyse tendances GPT-4: {result['execution_time']:.2f}s")
        return result
    
    def competitive_analysis_with_claude(self, trends_summary: str) -> Dict[str, Any]:
        """Utilise Claude pour l'analyse concurrentielle approfondie"""
        response = requests.post(f"{self.base_url}/orchestrate", json={
            "message": f"""
            R√©sum√© des tendances identifi√©es: {trends_summary}
            
            Effectuez une analyse concurrentielle strat√©gique:
            
            1. POSITIONNEMENT CONCURRENTIEL:
               - Leaders technologiques identifi√©s
               - Strat√©gies d'adoption par secteur
               - Avantages/inconv√©nients par solution
            
            2. ANALYSE DES GAPS:
               - Opportunit√©s non exploit√©es
               - Niches technologiques √©mergentes
               - Besoins clients non satisfaits
            
            3. RECOMMANDATIONS STRAT√âGIQUES:
               - Technologies √† adopter en priorit√©
               - Partenariats strat√©giques sugg√©r√©s
               - Investissements R&D recommand√©s
            
            4. PLAN D'ACTION:
               - Timeline d'impl√©mentation
               - Ressources n√©cessaires
               - M√©triques de succ√®s
            
            Approche analytique rigoureuse avec preuves √† l'appui.
            """,
            "agent_config": {
                "provider": "anthropic",
                "model": "claude-3-5-sonnet-20241022",
                "temperature": 0.3,
                "max_tokens": 2500
            },
            "session_id": self.session_id
        })
        
        result = response.json()
        print(f"üéØ Analyse concurrentielle Claude: {result['execution_time']:.2f}s")
        return result
    
    def technical_deep_dive_with_deepseek(self, tech_focus: str) -> Dict[str, Any]:
        """Utilise DeepSeek pour l'analyse technique approfondie"""
        response = requests.post(f"{self.base_url}/orchestrate", json={
            "message": f"""
            Focus technique: {tech_focus}
            
            Effectuez une analyse technique approfondie:
            
            1. ARCHITECTURE TECHNIQUE:
               - Composants et modules principaux
               - Patterns d'architecture utilis√©s
               - Int√©grations et APIs disponibles
            
            2. IMPL√âMENTATION:
               - Code samples et exemples pratiques
               - Bonnes pratiques d'impl√©mentation
               - Pi√®ges √† √©viter et solutions
            
            3. PERFORMANCE ET SCALABILIT√â:
               - Benchmarks et m√©triques
               - Limites techniques identifi√©es
               - Optimisations possibles
            
            4. √âCOSYST√àME ET TOOLING:
               - Outils de d√©veloppement
               - Biblioth√®ques et extensions
               - Communaut√© et support
            
            5. MIGRATION ET ADOPTION:
               - Strat√©gies de migration
               - Coexistence avec l'existant
               - Formation √©quipes n√©cessaire
            
            Analyse technique d√©taill√©e avec exemples de code.
            """,
            "agent_config": {
                "provider": "deepseek",
                "model": "deepseek-chat",
                "temperature": 0.2,
                "max_tokens": 3500
            },
            "session_id": self.session_id
        })
        
        result = response.json()
        print(f"üîß Analyse technique DeepSeek: {result['execution_time']:.2f}s")
        return result
    
    def market_intelligence_with_gemini(self, analysis_context: str) -> Dict[str, Any]:
        """Utilise Gemini pour l'intelligence march√©"""
        response = requests.post(f"{self.base_url}/orchestrate", json={
            "message": f"""
            Contexte d'analyse: {analysis_context}
            
            Fournissez une intelligence march√© compl√®te:
            
            1. SIZING ET VALORISATION:
               - Taille de march√© actuelle et projet√©e
               - Segments de croissance principaux
               - Valorisations et investissements r√©cents
            
            2. ACTEURS CL√âS:
               - Leaders √©tablis et challengers
               - Startups prometteuses √† surveiller
               - Consolidations et acquisitions r√©centes
            
            3. DYNAMIQUES MARCH√â:
               - Facteurs de croissance identifi√©s
               - Barri√®res √† l'entr√©e
               - Cycles d'adoption par industrie
            
            4. SIGNAUX FAIBLES:
               - Innovations de rupture potentielles
               - Changements r√©glementaires impact
               - Shifts comportementaux utilisateurs
            
            5. RECOMMANDATIONS INVESTISSEMENT:
               - Priorit√©s d'allocation budget
               - Horizons temporels par technologie
               - Strat√©gies hedging recommand√©es
            
            Intelligence actionnable avec donn√©es march√© r√©centes.
            """,
            "agent_config": {
                "provider": "gemini",
                "model": "gemini-1.5-pro",
                "temperature": 0.5,
                "max_tokens": 2800
            },
            "session_id": self.session_id
        })
        
        result = response.json()
        print(f"üìä Intelligence march√© Gemini: {result['execution_time']:.2f}s")
        return result
    
    def synthesize_insights_with_mistral(self, all_analyses: Dict[str, Any]) -> Dict[str, Any]:
        """Utilise Mistral pour synth√©tiser tous les insights"""
        response = requests.post(f"{self.base_url}/orchestrate", json={
            "message": f"""
            Analyses r√©alis√©es:
            - Tendances: {all_analyses['trends']['response'][:300]}...
            - Concurrence: {all_analyses['competitive']['response'][:300]}...
            - Technique: {all_analyses['technical']['response'][:300]}...
            - March√©: {all_analyses['market']['response'][:300]}...
            
            Synth√©tisez en rapport ex√©cutif final:
            
            ## EXECUTIVE SUMMARY
            - 3 insights cl√©s prioritaires
            - Impact business estim√©
            - Actions imm√©diates recommand√©es
            
            ## STRATEGIC ROADMAP
            - Phase 1 (0-3 mois): Actions critiques
            - Phase 2 (3-6 mois): D√©veloppements strat√©giques
            - Phase 3 (6-12 mois): Innovations long terme
            
            ## RISK ASSESSMENT
            - Risques technologiques identifi√©s
            - Risques concurrentiels
            - Strat√©gies de mitigation
            
            ## KPIs DE SUIVI
            - M√©triques d'adoption
            - Indicateurs de performance
            - Seuils d'alerte
            
            Format: rapport ex√©cutif pr√™t pour pr√©sentation C-level.
            """,
            "agent_config": {
                "provider": "mistral",
                "model": "mistral-large-latest",
                "temperature": 0.4,
                "max_tokens": 2500
            },
            "session_id": self.session_id
        })
        
        result = response.json()
        print(f"üìã Synth√®se finale Mistral: {result['execution_time']:.2f}s")
        return result
    
    def run_complete_tech_watch(self, watch_config: Dict[str, Any], 
                              tech_data: str) -> Dict[str, Any]:
        """Ex√©cute une veille technologique compl√®te"""
        print("üîç D√©marrage de la veille technologique compl√®te...")
        
        # 1. Cr√©er la session
        self.start_tech_watch_session(watch_config)
        
        # 2. Analyse des tendances avec GPT-4
        trends_analysis = self.analyze_trends_with_gpt4(tech_data)
        
        # 3. Analyse concurrentielle avec Claude
        competitive_analysis = self.competitive_analysis_with_claude(
            trends_analysis['response'][:800]
        )
        
        # 4. Deep dive technique avec DeepSeek
        technical_analysis = self.technical_deep_dive_with_deepseek(
            watch_config['domains'][0]  # Focus sur le premier domaine
        )
        
        # 5. Intelligence march√© avec Gemini
        market_intelligence = self.market_intelligence_with_gemini(
            f"Trends: {trends_analysis['response'][:400]}... Competitive: {competitive_analysis['response'][:400]}..."
        )
        
        # 6. Synth√®se finale avec Mistral
        all_analyses = {
            'trends': trends_analysis,
            'competitive': competitive_analysis,
            'technical': technical_analysis,
            'market': market_intelligence
        }
        
        final_synthesis = self.synthesize_insights_with_mistral(all_analyses)
        
        # 7. M√©triques de session
        metrics_response = requests.get(f"{self.base_url}/sessions/{self.session_id}/metrics")
        session_metrics = metrics_response.json()
        
        return {
            "session_id": self.session_id,
            "trends_analysis": trends_analysis,
            "competitive_analysis": competitive_analysis,
            "technical_analysis": technical_analysis,
            "market_intelligence": market_intelligence,
            "final_synthesis": final_synthesis,
            "session_metrics": session_metrics,
            "providers_used": ["openai", "anthropic", "deepseek", "gemini", "mistral"],
            "total_execution_time": sum([
                trends_analysis['execution_time'],
                competitive_analysis['execution_time'],
                technical_analysis['execution_time'],
                market_intelligence['execution_time'],
                final_synthesis['execution_time']
            ]),
            "domains_analyzed": self.tech_domains
        }

# Exemple d'utilisation
if __name__ == "__main__":
    tech_watch = TechWatchOrchestrator()
    
    watch_config = {
        "analyst_id": "TW_001",
        "domains": ["AI/ML", "Cloud Computing", "Cybersecurity", "DevOps"],
        "frequency": "weekly",
        "focus": "enterprise_adoption",
        "company": "TechCorp Inc."
    }
    
    tech_data = """
    Donn√©es r√©centes Q4 2024:
    - Adoption massive de l'IA g√©n√©rative en entreprise (+340%)
    - Croissance des solutions edge computing (+125%)
    - Nouvelles r√©gulations cybers√©curit√© EU/US
    - Kubernetes devient standard de facto (87% adoption)
    - √âmergence des LLMs sp√©cialis√©s par domaine
    - Consolidation march√© cloud providers
    - Zero-trust architecture mainstream
    - Quantum computing: premiers cas d'usage pratiques
    """
    
    results = tech_watch.run_complete_tech_watch(watch_config, tech_data)
    
    print("\nüîç R√âSULTATS DE LA VEILLE TECHNOLOGIQUE")
    print("=" * 60)
    print(f"Session ID: {results['session_id']}")
    print(f"Domaines analys√©s: {', '.join(results['domains_analyzed'])}")
    print(f"Providers utilis√©s: {', '.join(results['providers_used'])}")
    print(f"Temps total d'analyse: {results['total_execution_time']:.2f}s")
    print(f"Messages √©chang√©s: {results['session_metrics']['message_count']}")
    print(f"Co√ªt total: ${results['session_metrics']['total_cost']:.4f}")
    print(f"Providers sollicit√©s: {len(results['session_metrics']['providers_used'])}")
```

### 4. üì± Assistant de Session Longue avec Auto-Summarization

**Objectif :** D√©montrer la gestion automatique de la m√©moire et du r√©sum√© en session longue.

```python
class LongSessionOrchestrator:
    def __init__(self, base_url: str = "http://localhost:8000/api"):
        self.base_url = base_url
        self.session_id = None
        self.message_count = 0
    
    def start_long_session(self, context: str) -> str:
        """D√©marre une session longue avec contexte"""
        response = requests.post(f"{self.base_url}/sessions", json={
            "user_id": "long_session_user",
            "metadata": {
                "type": "long_conversation",
                "context": context,
                "auto_summarization": True,
                "summarization_threshold": 10  # R√©sum√© tous les 10 messages pour la d√©mo
            }
        })
        
        self.session_id = response.json()["session_id"]
        print(f"üöÄ Session longue cr√©√©e: {self.session_id}")
        return self.session_id
    
    def send_message(self, message: str, provider: str = "openai") -> Dict[str, Any]:
        """Envoie un message dans la session"""
        response = requests.post(f"{self.base_url}/orchestrate", json={
            "message": message,
            "agent_config": {
                "provider": provider,
                "model": "gpt-3.5-turbo" if provider == "openai" else "claude-3-5-haiku-20241022",
                "temperature": 0.7,
                "max_tokens": 1000
            },
            "session_id": self.session_id
        })
        
        result = response.json()
        self.message_count += 1
        
        # V√©rifier si un r√©sum√© a √©t√© d√©clench√©
        was_summarized = result.get('metadata', {}).get('was_summarized', False)
        if was_summarized:
            print(f"üß† R√©sum√© automatique d√©clench√© au message {self.message_count}")
        
        print(f"üí¨ Message {self.message_count} ({provider}): {result['execution_time']:.2f}s")
        return result
    
    def demonstrate_auto_summarization(self) -> Dict[str, Any]:
        """D√©montre le m√©canisme de r√©sum√© automatique"""
        print("üìö D√©monstration de la summarization automatique...")
        
        # 1. Cr√©er une session longue
        self.start_long_session("Projet de d√©veloppement d'application mobile")
        
        # S√©rie de messages qui vont d√©clencher la summarization
        messages = [
            ("Bonjour, je travaille sur une app mobile de fitness", "openai"),
            ("Quelles sont les meilleures pratiques UX pour ce type d'app?", "anthropic"),
            ("Comment g√©rer l'authentification des utilisateurs?", "openai"),
            ("Quel backend recommandez-vous pour une app fitness?", "gemini"),
            ("Comment impl√©menter le tracking GPS pour les courses?", "deepseek"),
            ("Quelles APIs utiliser pour les donn√©es nutritionnelles?", "mistral"),
            ("Comment optimiser les performances de l'app?", "anthropic"),
            ("Quelle strat√©gie de mon√©tisation adopter?", "openai"),
            ("Comment g√©rer les notifications push efficacement?", "qwen"),
            ("Quels tests automatis√©s mettre en place?", "openai"),
            # Le 11√®me message devrait d√©clencher la summarization
            ("Comment d√©ployer l'app sur les stores?", "anthropic"),
            ("Apr√®s le r√©sum√©, continuons avec les m√©triques d'usage", "gemini"),
            ("Comment analyser le comportement des utilisateurs?", "openai"),
        ]
        
        responses = []
        summarization_triggered = False
        
        for i, (message, provider) in enumerate(messages, 1):
            print(f"\n--- Message {i} ---")
            response = self.send_message(message, provider)
            responses.append(response)
            
            # D√©tecter si la summarization a √©t√© d√©clench√©e
            if response.get('metadata', {}).get('was_summarized', False):
                summarization_triggered = True
                print(f"‚úÖ R√©sum√© automatique confirm√© au message {i}")
                
                # R√©cup√©rer l'historique pour voir le r√©sum√©
                history_response = requests.get(
                    f"{self.base_url}/sessions/{self.session_id}/history?limit=50"
                )
                history = history_response.json()
                
                print(f"üìù R√©sum√© g√©n√©r√©: {history.get('summary', 'Aucun r√©sum√©')[:200]}...")
        
        # M√©triques finales
        metrics_response = requests.get(f"{self.base_url}/sessions/{self.session_id}/metrics")
        session_metrics = metrics_response.json()
        
        return {
            "session_id": self.session_id,
            "total_messages": len(responses),
            "summarization_triggered": summarization_triggered,
            "providers_used": list(set(msg[1] for msg in messages)),
            "session_metrics": session_metrics,
            "responses": responses
        }

# Exemple d'utilisation
if __name__ == "__main__":
    long_session = LongSessionOrchestrator()
    
    results = long_session.demonstrate_auto_summarization()
    
    print("\nüìö R√âSULTATS D√âMONSTRATION AUTO-SUMMARIZATION")
    print("=" * 60)
    print(f"Session ID: {results['session_id']}")
    print(f"Messages envoy√©s: {results['total_messages']}")
    print(f"R√©sum√© d√©clench√©: {'‚úÖ Oui' if results['summarization_triggered'] else '‚ùå Non'}")
    print(f"Providers utilis√©s: {', '.join(results['providers_used'])}")
    print(f"Message count final: {results['session_metrics']['message_count']}")
    print(f"Co√ªt total: ${results['session_metrics']['total_cost']:.4f}")
    
    if results['summarization_triggered']:
        print("üéâ D√©monstration r√©ussie de la m√©moire automatique!")
    else:
        print("‚ö†Ô∏è Le seuil de summarization n'a pas √©t√© atteint dans cette d√©mo")
```

## üéØ Ex√©cution des Exemples

### Pr√©requis

```bash
# 1. D√©marrer le serveur Orchestrator Agent
python main.py

# 2. Installer les d√©pendances pour les exemples
pip install requests

# 3. Configurer les cl√©s API dans .env
# (Voir ./SECURITY.md pour la configuration compl√®te)
```

### Lancement des Sc√©narios

```python
# Ex√©cuter tous les exemples
if __name__ == "__main__":
    import asyncio
    
    async def run_all_scenarios():
        """Ex√©cute tous les sc√©narios d'usage avanc√©s"""
        
        print("üöÄ LANCEMENT DES SC√âNARIOS AVANC√âS")
        print("=" * 50)
        
        # Sc√©nario 1: Analyse de donn√©es
        print("\n1Ô∏è‚É£ Analyse de Donn√©es Multi-Provider")
        data_orchestrator = DataAnalysisOrchestrator()
        # ... (code du sc√©nario)
        
        # Sc√©nario 2: Tutorat adaptatif
        print("\n2Ô∏è‚É£ Tutorat IA Adaptatif")
        tutor = AdaptiveTutorOrchestrator()
        # ... (code du sc√©nario)
        
        # Sc√©nario 3: Veille technologique
        print("\n3Ô∏è‚É£ Veille Technologique")
        tech_watch = TechWatchOrchestrator()
        # ... (code du sc√©nario)
        
        # Sc√©nario 4: Session longue
        print("\n4Ô∏è‚É£ Auto-Summarization")
        long_session = LongSessionOrchestrator()
        # ... (code du sc√©nario)
        
        print("\n‚úÖ TOUS LES SC√âNARIOS TERMIN√âS")
    
    # Lancer les sc√©narios
    asyncio.run(run_all_scenarios())
```

---

## üìä M√©triques et Performance

Chaque sc√©nario g√©n√®re des m√©triques d√©taill√©es :

- **Temps d'ex√©cution** par provider
- **Co√ªt estim√©** par requ√™te
- **Nombre de tokens** utilis√©s
- **Taux de succ√®s** des requ√™tes
- **Performance comparative** entre providers

## üéØ Personnalisation

Ces exemples sont enti√®rement personnalisables :

1. **Modifiez les providers** selon vos besoins
2. **Ajustez les param√®tres** (temperature, max_tokens)
3. **Adaptez les prompts** √† votre domaine
4. **Configurez les seuils** de summarization
5. **Personnalisez les m√©triques** collect√©es

---

> üéÆ **Ces exemples d√©montrent la puissance r√©elle de l'Orchestrator Agent** avec ses sessions persistantes, sa m√©moire automatique, et son orchestration intelligente de 8 fournisseurs LLM diff√©rents.