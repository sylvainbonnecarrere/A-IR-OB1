"""FastAPI Router - Endpoints avec Dependency Injection"""

from datetime import datetime
from typing import Optional
import uuid
from fastapi import APIRouter, Depends, HTTPException, BackgroundTasks
from src.api.dependencies import (
    get_default_llm_service, 
    get_llm_service_from_config,
    get_tool_executor,
    llm_provider
)
from src.domain.llm_service_interface import LLMServiceInterface
from src.domain.llm_service_factory import LLMServiceFactory
from src.domain.agent_orchestrator import AgentOrchestrator
from src.domain.agent_router import AgentRouter
from src.domain.history_summarizer import HistorySummarizer
from src.infrastructure.tool_executor import ToolExecutor
from src.infrastructure.session_manager import InMemorySessionManager
from src.models.data_contracts import (
    HealthResponse,
    ServiceTestRequest,
    ServiceTestResponse,
    ProvidersResponse,
    ChatRequest,
    ChatResponse,
    ChatMessage,
    ErrorResponse,
    OrchestrationRequest,
    OrchestrationResponse,
    AgentDefinition,
    AgentConfig,
    LLMProvider,
    Session,
    HistoryConfig,
    SessionCreateRequest,
    SessionResponse
)

# Cr√©ation du router
router = APIRouter()


@router.get("/", summary="Page d'accueil")
async def root():
    """Endpoint racine avec liens de navigation"""
    return {
        "message": "ü§ñ A-IR-OB1 - AI Agent Orchestrator",
        "version": "1.0.0",
        "status": "running",
        "endpoints": {
            "health": "/health",
            "docs": "/docs",
            "test_service": "/test-service",
            "providers": "/providers",
            "chat": "/chat"
        },
        "repository": "https://github.com/sylvainbonnecarrere/A-IR-OB1"
    }


@router.get("/health", response_model=HealthResponse, summary="Health Check")
async def health_check():
    """V√©rification de sant√© de l'application"""
    return HealthResponse(
        status="healthy",
        version="1.0.0",
        timestamp=datetime.now().isoformat()
    )


@router.post("/test-service", response_model=ServiceTestResponse, summary="Test LLM Service")
async def test_llm_service(
    request: ServiceTestRequest = ServiceTestRequest(),
    llm_service: LLMServiceInterface = Depends(get_default_llm_service)
):
    """Test du service LLM avec injection de d√©pendances"""
    try:
        # Test simple du service
        response = await llm_service.simple_completion(request.message)
        
        return ServiceTestResponse(
            success=True,
            response=response,
            provider=llm_service.get_provider_name(),
            error=None
        )
    except Exception as e:
        return ServiceTestResponse(
            success=False,
            response=None,
            provider=llm_service.get_provider_name(),
            error=str(e)
        )


@router.get("/providers", response_model=ProvidersResponse, summary="Available LLM Providers")
async def get_providers():
    """Liste des fournisseurs LLM disponibles"""
    providers = LLMServiceFactory.get_available_providers()
    return ProvidersResponse(
        providers=providers,
        default="openai",
        count=len(providers)
    )


@router.post("/chat", response_model=ChatResponse, summary="Chat with LLM")
async def chat_completion(
    request: ChatRequest,
    llm_service: LLMServiceInterface = Depends(get_default_llm_service)
):
    """Endpoint de chat avec LLM"""
    try:
        # Cr√©er le message pour le LLM
        messages = [ChatMessage(role="user", content=request.message)]
        
        # Appel au service LLM
        response = await llm_service.chat_completion(
            messages=messages,
            model=request.model,
            max_tokens=request.max_tokens,
            temperature=request.temperature
        )
        
        return response
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Chat completion failed: {str(e)}")


@router.get("/providers/info", summary="Detailed Provider Information")
async def get_providers_info():
    """Informations d√©taill√©es sur tous les fournisseurs"""
    try:
        info = LLMServiceFactory.get_provider_info()
        return {
            "providers": info,
            "count": len(info),
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get provider info: {str(e)}")


@router.post("/providers/{provider}/test", response_model=ServiceTestResponse, summary="Test Specific Provider")
async def test_specific_provider(
    provider: str,
    request: ServiceTestRequest = ServiceTestRequest()
):
    """Test d'un fournisseur sp√©cifique"""
    try:
        # Obtenir le service pour ce fournisseur
        llm_service = LLMServiceFactory.create_service(provider)
        
        # Test du service
        response = await llm_service.simple_completion(request.message)
        
        return ServiceTestResponse(
            success=True,
            response=response,
            provider=provider,
            error=None
        )
        
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        return ServiceTestResponse(
            success=False,
            response=None,
            provider=provider,
            error=str(e)
        )


@router.get("/debug/factory", summary="Factory Debug Info")
async def debug_factory():
    """Informations de debug sur la factory"""
    return {
        "available_providers": LLMServiceFactory.get_available_providers(),
        "cache_size": len(LLMServiceFactory._instances),
        "registered_adapters": list(LLMServiceFactory._providers.keys()),
        "timestamp": datetime.now().isoformat()
    }


# ============================================================================
# JALON 2.5 - ENDPOINT D'ORCHESTRATION AVEC BOUCLE REACT
# ============================================================================

def get_tool_executor() -> ToolExecutor:
    """
    Dependency pour obtenir une instance de ToolExecutor
    
    Returns:
        ToolExecutor: Instance configur√©e avec les outils disponibles
    """
    return ToolExecutor()


@router.post("/api/orchestrate", response_model=OrchestrationResponse, summary="Multi-Agent Orchestration with Router + ReAct Loop")
async def orchestrate_agent(
    request: OrchestrationRequest,
    llm_service: LLMServiceInterface = Depends(get_default_llm_service),
    tool_executor: ToolExecutor = Depends(get_tool_executor)
):
    """
    Endpoint principal d'orchestration multi-agents avec routeur intelligent
    
    Ce endpoint impl√©mente le nouveau flux √† 2 niveaux:
    
    **Niveau 1 - Routeur (Moteur de D√©cision):**
    1. Analyse l'intention utilisateur via Function Calling
    2. S√©lectionne l'agent sp√©cialis√© le plus appropri√©
    3. Retourne la configuration optimale pour cet agent
    
    **Niveau 2 - Orchestrateur (Moteur d'Ex√©cution):**
    1. **Reasoning**: L'agent s√©lectionn√© analyse la requ√™te
    2. **Acting**: Ex√©cution des outils sp√©cialis√©s de l'agent
    3. **Feedback**: R√©tro-injection des r√©sultats
    4. **Repeat**: R√©p√©tition jusqu'√† obtention d'une r√©ponse finale
    
    Args:
        request: Requ√™te d'orchestration contenant le message
        llm_service: Service LLM pour le routeur (mod√®le rapide)
        tool_executor: Ex√©cuteur d'outils inject√©
        
    Returns:
        OrchestrationResponse: R√©ponse finale apr√®s routage + boucle ReAct
        
    Raises:
        HTTPException: En cas d'erreur lors de l'orchestration
        
    Example:
        ```json
        {
            "message": "Quelle est l'heure maintenant ?",
            "conversation_history": []
        }
        ```
        
    Note: 
        La configuration agent_config est maintenant d√©termin√©e automatiquement
        par le routeur en fonction de l'intention d√©tect√©e dans le message.
    """
    try:
        # ========================================
        # √âTAPE 1: ROUTAGE INTELLIGENT
        # ========================================
        
        # Cr√©ation du routeur avec un LLM rapide pour la d√©cision
        router_service = LLMServiceFactory.create_service(LLMProvider.OPENAI)
        agent_router = AgentRouter(router_service)
        
        # D√©finition des agents sp√©cialis√©s disponibles
        available_agents = _get_demo_agents()
        
        # Message utilisateur pour le routage
        user_message = ChatMessage(role="user", content=request.message)
        
        # S√©lection de l'agent appropri√© via Function Calling
        selected_agent = await agent_router.dispatch(user_message, available_agents)
        
        print(f"üéØ Agent s√©lectionn√©: {selected_agent.agent_name}")
        print(f"üìã Description: {selected_agent.description}")
        
        # ========================================
        # √âTAPE 2: ORCHESTRATION SP√âCIALIS√âE
        # ========================================
        
        # Cr√©ation du service LLM sp√©cialis√© pour l'agent s√©lectionn√©
        specialized_service = LLMServiceFactory.create_service(
            selected_agent.default_config.provider
        )
        
        # Cr√©ation de l'orchestrateur avec le service sp√©cialis√©
        orchestrator = AgentOrchestrator(
            llm_service=specialized_service,
            tool_executor=tool_executor
        )
        
        # Construction de l'historique avec le message utilisateur
        history = list(request.conversation_history)
        if request.message:
            history.append(ChatMessage(role="user", content=request.message))
        
        # Ex√©cution de la boucle ReAct avec la configuration de l'agent s√©lectionn√©
        response = await orchestrator.run_orchestration(
            config=selected_agent.default_config,
            history=history
        )
        
        # Enrichissement de la r√©ponse avec les informations de routage
        response.provider = f"{response.provider} (via {selected_agent.agent_name})"
        
        return response
        
    except HTTPException:
        # Re-lancer les HTTPException directement
        raise
    except Exception as e:
        # Capturer toutes les autres erreurs
        raise HTTPException(
            status_code=500, 
            detail=f"Erreur lors de l'orchestration multi-agents: {str(e)}"
        )


def _get_demo_agents() -> list[AgentDefinition]:
    """
    Cr√©e une liste d'agents de d√©monstration pour le Jalon 3.4
    
    Returns:
        List[AgentDefinition]: Liste des agents sp√©cialis√©s disponibles
    """
    return [
        # Agent sp√©cialis√© dans les informations temporelles et syst√®me
        AgentDefinition(
            agent_name="Time_Info_Agent",
            description="Agent sp√©cialis√© dans les requ√™tes temporelles (heure, date, fuseaux horaires) et les informations syst√®me",
            default_config=AgentConfig(
                provider=LLMProvider.OPENAI,
                model_version="gpt-3.5-turbo",
                temperature=0.3,
                max_tokens=800,
                tools_enabled=True,
                available_tools=["get_current_time"],
                system_prompt="Tu es Time_Info_Agent, un assistant sp√©cialis√© dans les informations temporelles et syst√®me. Tu fournis des informations pr√©cises sur l'heure, la date, les fuseaux horaires et les donn√©es syst√®me. Utilise les outils disponibles pour obtenir des informations en temps r√©el."
            )
        ),
        
        # Agent g√©n√©raliste pour les t√¢ches de r√©sum√© et d'analyse textuelle
        AgentDefinition(
            agent_name="Text_Analysis_Agent", 
            description="Agent sp√©cialis√© dans l'analyse, le r√©sum√© et le traitement de texte. Id√©al pour les t√¢ches de r√©daction, r√©sum√©, analyse litt√©raire et traitement linguistique",
            default_config=AgentConfig(
                provider=LLMProvider.GEMINI,
                model_version="gemini-2.0-flash-exp",
                temperature=0.7,
                max_tokens=1500,
                tools_enabled=False,  # Pas d'outils, focus sur le traitement textuel
                available_tools=[],
                system_prompt="Tu es Text_Analysis_Agent, un expert en analyse et traitement de texte. Tu excelles dans la r√©daction, le r√©sum√©, l'analyse litt√©raire, la cr√©ation de contenu et toutes les t√¢ches li√©es au language. Tu fournis des r√©ponses d√©taill√©es et bien structur√©es."
            )
        ),
        
        # Agent pour les calculs et la logique
        AgentDefinition(
            agent_name="Logic_Math_Agent",
            description="Agent sp√©cialis√© dans les calculs math√©matiques, la logique, les probl√®mes analytiques et le raisonnement quantitatif",
            default_config=AgentConfig(
                provider=LLMProvider.ANTHROPIC,
                model_version="claude-3-opus-20240229",
                temperature=0.1,  # Temp√©rature basse pour la pr√©cision
                max_tokens=1000,
                tools_enabled=False,
                available_tools=[],
                system_prompt="Tu es Logic_Math_Agent, un sp√©cialiste des math√©matiques et de la logique. Tu r√©sous des probl√®mes quantitatifs, effectues des calculs complexes, analyses des donn√©es num√©riques et raisonnes de mani√®re analytique. Tu donnes des r√©ponses pr√©cises et d√©taill√©es avec des explications √©tape par √©tape."
            )
        )
    ]


# === Instances globales pour la gestion des sessions (Jalon 3.5) ===

# Configuration par d√©faut pour l'historique
DEFAULT_HISTORY_CONFIG = HistoryConfig(
    message_threshold=10,
    char_threshold=15000,
    summary_provider=LLMProvider.GEMINI,
    summary_model="gemini-2.0-flash-exp"
)

# Gestionnaire de sessions (en m√©moire pour le d√©veloppement)
session_manager = InMemorySessionManager()

# Service de synth√®se d'historique
history_summarizer = HistorySummarizer(
    llm_service_factory=LLMServiceFactory(),
    default_config=DEFAULT_HISTORY_CONFIG
)


# === Endpoints de gestion des sessions (Jalon 3.5) ===

@router.post(
    "/sessions",
    response_model=SessionResponse,
    summary="Cr√©er une nouvelle session",
    description="Cr√©e une nouvelle session de conversation persistante pour un agent donn√©"
)
async def create_session(
    request: SessionCreateRequest,
    background_tasks: BackgroundTasks
) -> SessionResponse:
    """
    Cr√©e une nouvelle session de conversation
    
    Args:
        request: Param√®tres de cr√©ation de session
        background_tasks: T√¢ches en arri√®re-plan pour initialisation
        
    Returns:
        Informations de la session cr√©√©e
        
    Raises:
        HTTPException: En cas d'erreur de cr√©ation
    """
    try:
        # Configuration d'historique (utilise celle fournie ou par d√©faut)
        history_config = request.history_config or DEFAULT_HISTORY_CONFIG
        
        # Cr√©ation de la session
        session = await session_manager.create_new_session(
            agent_name=request.agent_name,
            history_config=history_config
        )
        
        # T√¢che en arri√®re-plan pour logging
        background_tasks.add_task(
            _log_session_creation, 
            session.session_id, 
            request.agent_name
        )
        
        # R√©cup√©ration des m√©triques
        metrics = session.get_history_metrics()
        
        return SessionResponse(
            session_id=session.session_id,
            agent_name=session.agent_name,
            total_messages=metrics["messages"],
            created_at=session.created_at,
            last_message_at=session.last_message_at,
            status="active",
            total_characters=metrics["chars"],
            total_words=metrics["words"],
            estimated_tokens=metrics["estimated_tokens"]
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Erreur cr√©ation session: {str(e)}"
        )


@router.get(
    "/sessions/{session_id}",
    response_model=SessionResponse,
    summary="R√©cup√©rer une session",
    description="R√©cup√®re les informations d'une session existante par son ID"
)
async def get_session(session_id: str) -> SessionResponse:
    """
    R√©cup√®re une session par son ID
    
    Args:
        session_id: Identifiant unique de la session
        
    Returns:
        Informations de la session
        
    Raises:
        HTTPException: Si la session n'existe pas
    """
    try:
        # Validation de l'UUID
        uuid.UUID(session_id)
        
        # R√©cup√©ration de la session
        session = await session_manager.get_session(session_id)
        
        if not session:
            raise HTTPException(
                status_code=404,
                detail=f"Session {session_id} non trouv√©e"
            )
        
        # R√©cup√©ration des m√©triques
        metrics = session.get_history_metrics()
        
        return SessionResponse(
            session_id=session.session_id,
            agent_name=session.agent_name,
            total_messages=metrics["messages"],
            created_at=session.created_at,
            last_message_at=session.last_message_at,
            status="active",
            total_characters=metrics["chars"],
            total_words=metrics["words"],
            estimated_tokens=metrics["estimated_tokens"]
        )
        
    except ValueError:
        raise HTTPException(
            status_code=400,
            detail="Format d'ID de session invalide"
        )
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Erreur r√©cup√©ration session: {str(e)}"
        )


@router.post(
    "/sessions/{session_id}/orchestrate",
    response_model=OrchestrationResponse,
    summary="Orchestration avec session",
    description="Lance une orchestration dans le contexte d'une session persistante avec synth√®se automatique"
)
async def orchestrate_with_session(
    session_id: str,
    request: OrchestrationRequest,
    background_tasks: BackgroundTasks,
    llm_service: LLMServiceInterface = Depends(get_llm_service_from_config),
    tool_executor: ToolExecutor = Depends(get_tool_executor)
) -> OrchestrationResponse:
    """
    Lance une orchestration dans une session persistante
    
    Args:
        session_id: ID de la session
        request: Requ√™te d'orchestration
        background_tasks: T√¢ches asynchrones
        llm_service: Service LLM inject√©
        tool_executor: Ex√©cuteur d'outils inject√©
        
    Returns:
        R√©ponse d'orchestration avec session mise √† jour
        
    Raises:
        HTTPException: Si la session n'existe pas ou erreur d'orchestration
    """
    try:
        # Validation et r√©cup√©ration de session
        uuid.UUID(session_id)
        session = await session_manager.get_session(session_id)
        
        if not session:
            raise HTTPException(
                status_code=404,
                detail=f"Session {session_id} non trouv√©e"
            )
        
        # Cr√©ation de l'orchestrateur avec synth√®se d'historique
        orchestrator = AgentOrchestrator(
            llm_service=llm_service,
            tool_executor=tool_executor,
            history_summarizer=history_summarizer
        )
        
        # Orchestration avec session
        response = await orchestrator.run_orchestration_with_session(
            request=request,
            session=session
        )
        
        # Sauvegarde asynchrone de la session mise √† jour
        background_tasks.add_task(
            _update_session_async,
            session_id,
            session
        )
        
        return response
        
    except ValueError:
        raise HTTPException(
            status_code=400,
            detail="Format d'ID de session invalide"
        )
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Erreur orchestration avec session: {str(e)}"
        )


# === Fonctions utilitaires pour t√¢ches en arri√®re-plan ===

async def _log_session_creation(session_id: str, agent_name: str):
    """Log la cr√©ation d'une session"""
    print(f"üìù Session cr√©√©e: {session_id} pour agent {agent_name}")


async def _update_session_async(session_id: str, session: Session):
    """Met √† jour une session de mani√®re asynchrone"""
    try:
        await session_manager.update_session(session)
        print(f"üíæ Session {session_id} sauvegard√©e avec {session.total_messages} messages")
    except Exception as e:
        print(f"‚ùå Erreur sauvegarde session {session_id}: {e}")