"""
Service de R√©silience LLM avec Retry et Backoff (JALON 4.2)

Ce module impl√©mente un service d'enveloppement autour des services LLM existants
pour fournir une r√©silience aux erreurs temporaires via un pattern de retry 
avec backoff exponentiel configurable.
"""

import asyncio
import logging
from typing import Optional, Dict, Any, Type
from datetime import datetime

from src.domain.llm_service_interface import LLMServiceInterface
from src.domain.llm_service_factory import LLMServiceFactory
from src.domain.tracer import Tracer
from src.models.data_contracts import (
    AgentConfig, 
    RetryConfig, 
    OrchestrationRequest, 
    OrchestrationResponse,
    AgentExecutionError
)

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ResilientLLMService:
    """
    Service de r√©silience pour les appels LLM avec retry et backoff (JALON 4.2)
    
    Ce service encapsule les appels LLM avec une logique de retry configurable,
    un backoff exponentiel et un tra√ßage complet via le Tracer.
    
    Fonctionnalit√©s:
    - Retry configurable par agent via RetryConfig
    - Backoff exponentiel: delay_base * (2 ** (attempt - 1))
    - Tra√ßage de chaque tentative, d√©lai et r√©sultat
    - Gestion d'erreurs finales s√©curis√©e
    """
    
    def __init__(self, tracer: Optional[Tracer] = None):
        """
        Initialise le service r√©silient
        
        Args:
            tracer: Instance de tracer pour l'observabilit√© (optionnel)
        """
        self.tracer = tracer
        
        # D√©finition des erreurs temporaires qui justifient un retry
        self.retriable_errors = (
            # Erreurs de r√©seau temporaires
            ConnectionError,
            TimeoutError,
            # Erreurs HTTP temporaires (seront √©tendues selon les besoins)
            Exception  # Pour l'instant, on consid√®re toutes les exceptions comme retriables
        )
    
    async def resilient_chat_completion(
        self, 
        config: AgentConfig, 
        request: OrchestrationRequest
    ) -> OrchestrationResponse:
        """
        Effectue un appel LLM r√©silient avec retry et backoff
        
        Args:
            config: Configuration d'agent incluant RetryConfig
            request: Requ√™te d'orchestration
            
        Returns:
            R√©ponse d'orchestration r√©ussie
            
        Raises:
            AgentExecutionError: Apr√®s √©puisement des tentatives de retry
        """
        retry_config = config.retry_config
        llm_service = None
        last_error = None
        
        for attempt in range(1, retry_config.max_attempts + 1):
            try:
                # Tra√ßage du d√©but de tentative
                if self.tracer:
                    await self.tracer.log_step(
                        component="ResilientLLMService",
                        event="retry_attempt_start",
                        details={
                            "attempt": attempt,
                            "max_attempts": retry_config.max_attempts,
                            "provider": config.provider.value if config.provider else "unknown"
                        }
                    )
                
                # Cr√©ation du service LLM pour cette tentative
                if llm_service is None:
                    llm_service = LLMServiceFactory.create_service(config.provider)
                
                logger.info(f"üîÑ Tentative {attempt}/{retry_config.max_attempts} - Appel LLM {config.provider.value}")
                
                # Appel LLM r√©el
                response = await llm_service.orchestration_completion(request)
                
                # Succ√®s - Tra√ßage et retour
                if self.tracer:
                    await self.tracer.log_step(
                        component="ResilientLLMService",
                        event="llm_call_success",
                        details={
                            "attempt": attempt,
                            "provider": config.provider.value if config.provider else "unknown",
                            "response_length": len(response.content) if response.content else 0
                        }
                    )
                
                logger.info(f"‚úÖ Appel LLM r√©ussi √† la tentative {attempt}")
                return response
                
            except Exception as e:
                last_error = e
                logger.warning(f"‚ö†Ô∏è √âchec tentative {attempt}/{retry_config.max_attempts}: {str(e)}")
                
                # Tra√ßage de l'√©chec
                if self.tracer:
                    await self.tracer.log_step(
                        component="ResilientLLMService",
                        event="retry_attempt_failed",
                        details={
                            "attempt": attempt,
                            "error_type": type(e).__name__,
                            "error_message": str(e)[:200]  # Limiter la taille pour la s√©curit√©
                        }
                    )
                
                # Si c'est la derni√®re tentative, ne pas attendre
                if attempt >= retry_config.max_attempts:
                    break
                
                # Calcul du d√©lai de backoff exponentiel
                delay = retry_config.delay_base * (2 ** (attempt - 1))
                
                # Tra√ßage du d√©lai
                if self.tracer:
                    await self.tracer.log_step(
                        component="ResilientLLMService",
                        event="retry_backoff_delay",
                        details={
                            "delay_seconds": delay,
                            "attempt": attempt,
                            "backoff_formula": f"{retry_config.delay_base} * (2 ** {attempt - 1})"
                        }
                    )
                
                logger.info(f"‚è≥ Attente de {delay:.1f}s avant la tentative {attempt + 1}")
                await asyncio.sleep(delay)
        
        # Toutes les tentatives ont √©chou√© - Gestion d'erreur finale
        error_message = self._create_safe_error_message(last_error, retry_config.max_attempts)
        
        # Tra√ßage de l'√©chec final
        if self.tracer:
            await self.tracer.log_step(
                component="ResilientLLMService",
                event="max_retries_exceeded",
                details={
                    "max_attempts": retry_config.max_attempts,
                    "final_error_type": type(last_error).__name__ if last_error else "Unknown",
                    "safe_error_message": error_message
                }
            )
        
        logger.error(f"‚ùå √âchec d√©finitif apr√®s {retry_config.max_attempts} tentatives")
        
        # Lever une exception s√©curis√©e
        raise AgentExecutionError(
            message=error_message,
            original_error=last_error,
            attempts=retry_config.max_attempts
        )
    
    def _create_safe_error_message(self, error: Optional[Exception], attempts: int) -> str:
        """
        Cr√©e un message d'erreur s√©curis√© sans fuite d'informations sensibles
        
        Args:
            error: Erreur originale
            attempts: Nombre de tentatives effectu√©es
            
        Returns:
            Message d'erreur s√©curis√© pour l'utilisateur
        """
        if error is None:
            return f"Service LLM indisponible apr√®s {attempts} tentatives"
        
        error_type = type(error).__name__
        
        # Messages s√©curis√©s selon le type d'erreur
        safe_messages = {
            "ConnectionError": "Erreur de connexion au service LLM",
            "TimeoutError": "D√©lai d'attente d√©pass√© pour le service LLM",
            "HTTPException": "Erreur de communication avec le service LLM",
            "ValueError": "Erreur de configuration ou de donn√©es",
            "KeyError": "Erreur de configuration manquante",
        }
        
        base_message = safe_messages.get(error_type, "Erreur technique du service LLM")
        
        return f"{base_message} (apr√®s {attempts} tentatives)"
    
    def is_retriable_error(self, error: Exception) -> bool:
        """
        D√©termine si une erreur justifie une nouvelle tentative
        
        Args:
            error: Exception √† analyser
            
        Returns:
            True si l'erreur est consid√©r√©e comme temporaire
        """
        # Pour l'instant, consid√©rer la plupart des erreurs comme retriables
        # √Ä affiner selon les types d'erreurs sp√©cifiques des APIs LLM
        return isinstance(error, self.retriable_errors)


class ResilientServiceFactory:
    """
    Factory pour cr√©er des services r√©silients avec tra√ßage
    """
    
    @staticmethod
    def create_resilient_service(tracer: Optional[Tracer] = None) -> ResilientLLMService:
        """
        Cr√©e une instance de service r√©silient
        
        Args:
            tracer: Instance de tracer (optionnel)
            
        Returns:
            Service r√©silient configur√©
        """
        return ResilientLLMService(tracer=tracer)